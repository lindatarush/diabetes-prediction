{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b973c3e7",
   "metadata": {},
   "source": [
    "# Lab Test\n",
    "This notebook is dedicated to clean the data from lab tests into the [record format](http://160.89.29.120:30046/edit/src/main.py) as we defined for each data source. It includes the following sections:\n",
    "1. Read the files and filter the tests\n",
    "2. Cleaning\n",
    "3. Labeling\n",
    "4. Combine and write to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2b3494",
   "metadata": {},
   "source": [
    "## 1. Read the file and filter the tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2991c73f",
   "metadata": {},
   "source": [
    "Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f0ddb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import numpy as np\n",
    "import util.cleaning_tools as tools\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca96d58",
   "metadata": {},
   "source": [
    "Read the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f32e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the file path and tables path for file reading\n",
    "file_path = r'../DATAFILE'\n",
    "tid_to_eid_path = r'iams_entity_concept'\n",
    "labresult_cps_path = 'lis_cps_result_data'\n",
    "labresult_hms_path = 'lis_hms_result_data'\n",
    "\n",
    "# read the fragment files and concat them\n",
    "labresult_cps = tools.fileReader(file_path, labresult_cps_path)\n",
    "labresult_hms = tools.fileReader(file_path, labresult_hms_path)\n",
    "tid_to_eid = tools.fileReader(file_path, tid_to_eid_path)\n",
    "\n",
    "# concat them\n",
    "labresult = pd.concat([labresult_cps, labresult_hms], axis=0)\n",
    "# delete the reference to the raw data for the sake of garbage collection\n",
    "del labresult_cps\n",
    "del labresult_hms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0c1840",
   "metadata": {},
   "source": [
    "Since the combined lab test table large is quiet large, I will first filter the target tests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94e1c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the target term_id and find out the corresponding mapping table\n",
    "target_tid = [5200485,5203348,5200788,5201993,5204343,5203255,5200306]\n",
    "target_id = pd.Series(target_tid).rename('term_id')\n",
    "target_tid_mapping = pd.merge(target_id,tid_to_eid,how='left',on='term_id')\n",
    "target_tid_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1815a944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the mapping table and labresult on the entity_id\n",
    "labresult_filtered = pd.merge(labresult, target_tid_mapping, how='inner',on='entity_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97ac23a",
   "metadata": {},
   "source": [
    "This cell checks on the lab test unit applied on different target tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da74172b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labresult_filtered[[\"term_id\", \"si_unit\", \"test_unit\"]].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ad854a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicates just in case there is any duplicates records\n",
    "labresult_filtered = labresult_filtered.drop_duplicates()\n",
    "labresult_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e88d07c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# write to csv file\n",
    "labresult_filtered.to_csv(r'../tables/output/labresult_filtered.csv')\n",
    "# labresult_filtered = pd.read_csv(r'../tables/output/labresult_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98471fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the test unit for each kind of term_id\n",
    "labresult_filtered.groupby('term_id',as_index=False)[\"term_id\",\"si_unit\"].apply(lambda x : x.head(1)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8eac6f",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1c3629",
   "metadata": {},
   "source": [
    "The cell is deprecated becasue I will use standard numeric result to be consistent with the following analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed16f765",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # extract the numeric part of the test result \n",
    "# pattern = r'([0-9/.]*)'\n",
    "# labresult_filtered['numeric_test_result'] = labresult_filtered['result_str'].str.extract(pattern)\n",
    "# # transform the test result to numeric\n",
    "# labresult_filtered.numeric_test_result = pd.to_numeric(labresult_filtered.numeric_test_result,downcast='float')\n",
    "# labresult_filtered[['numeric_test_result','result_str']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33124ac2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the raw data record the null value as \"\" replace it with numpy null value class\n",
    "labresult_filtered[\"si_numeric\"].replace('\"\"', np.nan, inplace=True)\n",
    "labresult_filtered[\"si_numeric\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c9dd1c",
   "metadata": {},
   "source": [
    "I drop the null records since there is no reasonable explanation of the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcd6474",
   "metadata": {},
   "outputs": [],
   "source": [
    "labresult_filtered = labresult_filtered.query(\"si_numeric.notnull()\", engine='python')\n",
    "# after the filtering, we can safely cast the type to float with numpy built-in class np.float\n",
    "labresult_filtered[\"si_numeric\"] = labresult_filtered[\"si_numeric\"].astype(np.float)\n",
    "labresult_filtered.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28029738",
   "metadata": {},
   "source": [
    "## Labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f125363",
   "metadata": {},
   "source": [
    "Here we determine the type of result of each record and assign the result to a new column diab_type.\n",
    "There are three possible results:\n",
    "1. Diabetes(diab)\n",
    "2. Pre-Diabete(pre)\n",
    "3. Normal(normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f5bbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the pre-diabetes test result range\n",
    "r_range = {5200485: [5.7, 6.4],\n",
    "           5203348: [39, 46],\n",
    "           5200788: [7.8, 11.1],\n",
    "           5201993: [7.8, 11.1],\n",
    "           5204343: [5.6, 6.9],\n",
    "           5203255: [5.6, 6.9],\n",
    "           5200306: [5.6, 6.9]\n",
    "          }\n",
    "\n",
    "diab_type = []\n",
    "# loop over each record, it expects no built-in performance optimization\n",
    "for i in range(labresult_filtered.shape[0]):\n",
    "    term_id = labresult_filtered.iloc[i].loc[\"term_id\"]\n",
    "    rg = r_range[term_id]\n",
    "    test_result = labresult_filtered.loc[i, \"si_numeric\"]\n",
    "    if test_result > rg[1]:\n",
    "        # diabetes test result\n",
    "        diab_type.append(\"diab\")\n",
    "    elif test_result <= rg[1] and test_result >= rg[0]:\n",
    "        # pre-diabetes result\n",
    "        diab_type.append(\"pre\")\n",
    "    else:\n",
    "        # \n",
    "        diab_type.append(\"normal\")\n",
    "\n",
    "labresult_filtered = labresult_filtered.assign(diab_type = diab_type)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "93399df5",
   "metadata": {},
   "source": [
    "##### Display the patient number for each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87622ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.getNum(labresult_filtered[labresult_filtered.diab_type == \"pre\"],r=False)\n",
    "tools.getNum(labresult_filtered[labresult_filtered.diab_type == \"diab\"],r=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16be9a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "diab_records = labresult_filtered[labresult_filtered.diab_type == \"diab\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1320407f",
   "metadata": {},
   "source": [
    " ### Diabetes confirmation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9ecb35",
   "metadata": {},
   "source": [
    "This section determines the diabetes record based on the criterial provided: only include the patients who has two abnormal test of diabetes within 12 weeks for diabete patients or has a least one abnormal HbA1c test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e886ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only include the patients who has two abnormal test of diabetes within 12 weeks \n",
    "# for diabetes patients or has a least one abnormal HbA1C test \n",
    "\n",
    "\n",
    "# def diagConfirmed(df,h=7*24*12):\n",
    "#     # sort by reference_dtm\n",
    "#     df = df.sort_values(\"diff_in_hour_reference_dtm\")\n",
    "#     l = df.shape[0]\n",
    "#     i = 0\n",
    "#     if l == 1 and df.iloc[0, 3] in [5200485, 5203348]:\n",
    "#         return df.iloc[0,:]\n",
    "#     while(i < l-1):\n",
    "#         if (df.iloc[i+1,2] - df.iloc[i,2]) <= h or df.iloc[i, 3] in [5200485, 5203348] :\n",
    "#             # return the earliest record of the diabetes\n",
    "#             return df.iloc[i,:]\n",
    "#         i += 1\n",
    "#     return None\n",
    "\n",
    "\n",
    "def diagConfirmed(df:pd.DataFrame, h:int = 7*24*12) -> pd.DataFrame:\n",
    "    '''\n",
    "    callable instance that will be applied on each grouped dataframe, \n",
    "    this method will implement the diabetes matching rules: include the \n",
    "    patients who has two abnormal test of diabetes within 12 weeks \n",
    "    for diabetes patients or has a least one abnormal HbA1C test. \n",
    "    \n",
    "    Args:\n",
    "        df: pandas dataframe that is already grouped by some keys.\n",
    "        h: maximum time interval in hours for two abnormal tests except for HBA1C, default 12 weeks.\n",
    "    Return:\n",
    "        the earliest record of confirmed diabetes of this patients.\n",
    "    '''\n",
    "    l = df.shape[0]\n",
    "    for i in range(l):\n",
    "        if df.iloc[i][\"term_id\"] in [5200485, 5203348]: #HbA1c tests\n",
    "            return df.iloc[i,:]\n",
    "        elif i < l-1:\n",
    "            if (df.iloc[i+1].loc[\"diff_in_hour_reference_dtm\"] - df.iloc[i].loc[\"diff_in_hour_reference_dtm\"]) <= h:\n",
    "                return df.iloc[i,:]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "diab_patients = diab_records\\\n",
    "                .sort_values([\"pseudo_patient_key\", \"diff_in_hour_reference_dtm\"])\\\n",
    "                .groupby(by=[\"pseudo_patient_key\"])\\\n",
    "                .apply(diagConfirmed)\n",
    "diab_patients.reset_index(drop=True, inplace=True)\n",
    "diab_patients.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54934a91",
   "metadata": {},
   "source": [
    "### Pre-diabetes confirmation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3131fe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the earliest confirmination of pre-diabetes\n",
    "l = [\"pseudo_patient_key\",\"reference_dtm\", \"diff_in_hour_reference_dtm\", \"term_id\",\"diab_type\"]\n",
    "pre_records = labresult_filtered[labresult_filtered.diab_type == \"pre\"][l]\n",
    "pre_patients = pre_records\\\n",
    "            .sort_values([\"pseudo_patient_key\",\"diff_in_hour_reference_dtm\"])\\\n",
    "            .groupby(by=[\"pseudo_patient_key\"])\\\n",
    "            .apply(lambda x : x.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0e5ecb",
   "metadata": {},
   "source": [
    "## Combine and write to disk\n",
    "Combine the prediabetes and diabetes records and write to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0d74b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_records = pd.concat([pre_patients, diab_patients])\n",
    "# reset the index\n",
    "combine_records.reset_index(drop=True, inplace=True) \n",
    "combine_records.dropna(inplace=True) # drop null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67cfa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename to fit the common fields naming rules\n",
    "combine_records.rename({\"reference_dtm\":\"dx_dtm\", \"diff_in_hour_reference_dtm\": \"diff_hour\"}, axis=\"columns\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d63a148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add src\n",
    "combine_records[\"src\"] = \"lab\"\n",
    "# write to csv file\n",
    "combine_records[[\"pseudo_patient_key\", \"dx_dtm\", \"diff_hour\", \"diab_type\", \"src\"]].to_csv(r\"../tables/output/first_diag_lab.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbce2da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_records.groupby(\"diab_type\").count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
