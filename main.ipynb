{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "@Author: Jiqiao Lu, George\n",
    "@Email: george6.lu@polyu.edu.hk \n",
    "@Description: the main script implements all the cleaning steps, generate results and save the model. For some reason, the jupyter\n",
    "built-in editor does not support correct spacing and indent and I have no idea of how to use vim(without plugin), so I have to\n",
    "use notebook cell as script file, it is supposed to be a runnable scripts enabling user input argument for time-spectrum \n",
    "if you look at this code outside of HA, please convert it to a script as descibed above, thank you.\n",
    "\n",
    "'''\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from scipy import stats\n",
    "import util.cleaning_tools as tools\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay,\\\n",
    "precision_recall_curve, auc, roc_auc_score, roc_curve, recall_score, precision_score, accuracy_score\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, Lasso\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from random import sample\n",
    "import time\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import scipy.stats as stats\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# from sklearn.inspection import permutation_importance\n",
    "from typing import Callable\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_dict = {}\n",
    "\n",
    "#define indicators id\n",
    "term_id = list(name_dict.keys())\n",
    "\n",
    "METRICS = [\n",
    "    keras.metrics.TruePositives(name='tp'),\n",
    "    keras.metrics.FalsePositives(name='fp'),\n",
    "    keras.metrics.TrueNegatives(name='tn'),\n",
    "    keras.metrics.FalseNegatives(name='fn'),\n",
    "    keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "    keras.metrics.Precision(name='precision'),\n",
    "    keras.metrics.Recall(name='recall'), # we focus on recall metrics\n",
    "    keras.metrics.AUC(name='auc'),\n",
    "    keras.metrics.AUC(name='prc', curve='PR') # precision-recall curve\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AUCStopping(keras.callbacks.Callback):\n",
    "    '''\n",
    "    callback class, overwrite the method to trigger the call back function ath the end of the end of\n",
    "    epoch\n",
    "    '''\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('val_auc') >= 0.81 and logs.get('val_recall') >= 0.85):\n",
    "            print(\"\\n Early stopping beacause validation auc excesses 80%\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_age(df, fields, dob=\"dob_Y\"):\n",
    "    '''\n",
    "    map the date time fieds into age inplace\n",
    "    Args:\n",
    "        field: date fields\n",
    "        dob: date of birth\n",
    "    '''\n",
    "        \n",
    "    age_fields = list(map(lambda x : x.split(r'_')[0] + \"_age\", fields))\n",
    "    for af, f in zip(age_fields, fields):\n",
    "        df[af] = (pd.to_datetime(df[f]) - pd.to_datetime(df[dob])).apply(lambda x : x / np.timedelta64(1, \"Y\"))\n",
    "        \n",
    "\n",
    "def cls_mapper(prog_pd: float, PERIOD_LONG) -> int:\n",
    "    if prog_pd < PERIOD_LONG:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "      # define helper fuctions\n",
    "def plot_barchart(s:pd.Series, n_bin:int, bin_width:int=1, sort=False, title=\"\"):\n",
    "    bin = pd.cut(s, bins=[bin_width * i for i in range(n_bin)])\n",
    "    out = bin.value_counts(sort=sort)\n",
    "    ax = out.plot.bar(rot=0, color='b', figsize=(6,4))\n",
    "    ax.set_xticklabels([bin_width * x for x in range(n_bin)])\n",
    "    ax.set_title(title)\n",
    "\n",
    "def plot_boxplot(df, cat, title):\n",
    "    # boxplot for death age\n",
    "    fig, axs = plt.subplots(1,len(cat))\n",
    "    fig.suptitle(title)\n",
    "    for idx, name in zip(range(len(cat)), cat):\n",
    "        data = df[df.label == idx][\"death_age\"]\n",
    "        axs[idx].boxplot(data, 0, '')\n",
    "        axs[idx].set_title(name)\n",
    "        \n",
    "def make_model(X_train, metrics=METRICS, output_bias=None):\n",
    "    if output_bias is not None:\n",
    "        output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "        \n",
    "    # build the model, this model can be seen as a logistic regression but with extra drop-out layers \n",
    "    # for avoiding overfitting     \n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(16, activation='relu', input_shape=(X_train.shape[-1],)),\n",
    "        keras.layers.Dense(64, activation='relu'),\n",
    "        keras.layers.Dropout(0.5), # avoid overfitting\n",
    "        keras.layers.Dense(1, activation='sigmoid', bias_initializer=output_bias)\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=1e-3), #adam is not sensitive to different scale of loss\n",
    "        loss=keras.losses.BinaryCrossentropy(),\n",
    "        metrics=metrics\n",
    "    )\n",
    "    return model\n",
    "  \n",
    "def plot_metrics(history):\n",
    "    metrics = ['loss', 'accuracy', \"recall\", \"precision\"]\n",
    "    for n, metric in enumerate(metrics):\n",
    "        name = metric.replace(\"_\", \" \").capitalize()\n",
    "        ax = plt.subplot(2, 2, n+1)\n",
    "        fig = plt.gcf()\n",
    "        fig.set_size_inches(10,10)\n",
    "        plt.plot(history.epoch, history.history[metric], color=colors[0], label=\"Train\")\n",
    "        plt.plot(history.epoch, history.history['val_'+metric], color=colors[0], linestyle=\"--\", label=\"Val\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(name)\n",
    "        if metric == 'loss':\n",
    "            plt.ylim([0, plt.ylim()[1]])\n",
    "        elif metric == 'auc':\n",
    "            plt.ylim([0.8,1])\n",
    "        else:\n",
    "            plt.ylim([0,1])\n",
    "        plt.legend()\n",
    "    plt.savefig(os.path.join(OUT_PATH, \"charts\", \"training_history.png\"), bbox_inches='tight', dpi=400)\n",
    "        \n",
    "def plot_roc(name, labels, predictions, **kwargs):\n",
    "    fp, tp, threshold = sklearn.metrics.roc_curve(labels, predictions)\n",
    "    AUC = auc(fp,tp)\n",
    "    plt.plot(100*fp, 100*tp, linewidth=2, label=\"{} (area = {:.3f})\".format(name, AUC), **kwargs)\n",
    "    plt.xlabel('False positives [%]')\n",
    "    plt.ylabel('True positives [%]')\n",
    "    plt.xlim([0,100])\n",
    "    plt.ylim([0,100])\n",
    "    plt.grid(True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal')\n",
    "    return fp, tp, threshold\n",
    "\n",
    "def plot_feature_cpf(feature_name:str):\n",
    "    y, x, _ = plt.hist(dataset[feature_name], ec=\"black\", bins=500, cumulative=-1, histtype=\"step\", density=True)\n",
    "    print(len(x[1:]), len(y))\n",
    "    pd.DataFrame({\"x\": x[1:], \"y\": y}).to_csv(os.path.join(\"charts\", \"charts\", \"baseline_{}_dist.csv\".format(feature_name)))\n",
    "    plt.savefig(os.path.join(\"charts\", \"baseline_{}_dist.png\".format(feature_name)))\n",
    "    \n",
    "def permutation_importance(model, X: pd.DataFrame, y: pd.Series, n_repeats: int, metric_fn, **params) -> dict:\n",
    "    '''\n",
    "    the method return the mean score and std through out the n_repeat, the score is computed by the provided callable type\n",
    "    metric\n",
    "    \n",
    "    Assumption & Method\n",
    "    It assumes that the higher the score, the better the performance of the model is, and we use difference to measure the model\n",
    "    reliance of the feature.\n",
    "    \n",
    "    Arg:\n",
    "        model: model interface implements predicit method that return the decision score of the prediciton \n",
    "        X: input of validation set to be permutated\n",
    "        y: ground truth\n",
    "        n_repeats: the times of the iteration\n",
    "        metric_fn: the callable type to compute the score\n",
    "        params: addtional parameter to pass into the metric_funtion\n",
    "    \n",
    "    Return:\n",
    "        mean score over n repeats for each features.\n",
    "    '''\n",
    "    features = list(X.columns)\n",
    "    y_pred = model.predict(X)\n",
    "    original_score = metric_fn(y, y_pred, **params)\n",
    "    imp = {}\n",
    "    for _ in range(n_repeats):\n",
    "        for f in features:\n",
    "            X_new = X.copy() #copy the reference to the original dataframe\n",
    "            X_new[f] = X[f].sample(frac=1, replace=False).to_list()\n",
    "            y_pred = model.predict(X_new)\n",
    "            score = metric_fn(y, y_pred, **params)\n",
    "            diff = original_score - score\n",
    "            # assert the new score should not be greater than before\n",
    "            prev = imp.get(f, 0)\n",
    "            # add the new score difference\n",
    "            imp[f] = prev + diff\n",
    "    for f in imp:\n",
    "        imp[f] = imp[f] / n_repeats\n",
    "    return imp\n",
    "\n",
    "# plot confusion matrix for deep learning models\n",
    "def plot_cm(y, predictions, name, threshold=0.5):\n",
    "    cm = confusion_matrix(y, predictions > threshold)\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['no incidence', 'incidence ocurred'])\n",
    "    disp.plot(ax=ax, values_format='d')\n",
    "    plt.title('Confusion Matrix for Weighted Neural Network')\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.savefig(os.path.join(OUT_PATH, \"charts\", name + \".png\"), bbox_inches='tight', dpi=1000)\n",
    "    \n",
    "def get_scores(model, X_test, y_test):\n",
    "    \n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "#     print(\"=========================================================\")\n",
    "#     print(\"Metrics for model \" + model.__class__.__name__)\n",
    "#     report = classification_report(y_test, y_pred_test, target_names=['no incidence', 'incidence ocurred'])\n",
    "#     print(report)\n",
    "\n",
    "#     plot confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred_test, labels=[0.0,1.0])\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['no incidence', 'incidence ocurred'])\n",
    "    disp.plot(values_format='d')\n",
    "    fig = disp.figure_\n",
    "    fig.set_figwidth(5)\n",
    "    fig.set_figheight(5)\n",
    "    plt.grid(False)\n",
    "    plt.title(\"Confusion Matrix for \" + model.__class__.__name__, fontsize=12, fontweight='bold')\n",
    "    plt.savefig(os.path.join(OUT_PATH, \"charts\", \"Confusion Matrix for \" + model.__class__.__name__ + \".png\"), bbox_inches='tight', dpi=400)\n",
    "    return classification_report(y_test, y_pred_test, target_names=['no incidence', 'incidence ocurred'], output_dict=True)\n",
    "\n",
    "def compute_metrics(model, X, y, k=100):\n",
    "    # implement bootstraping\n",
    "    roc_auc = []\n",
    "    recall = []\n",
    "    precision = []\n",
    "    accuracy = []\n",
    "    for _ in range(k):\n",
    "        X_bs, y_bs = resample(X, y, replace=True)\n",
    "        try:\n",
    "            y_test_score = model.decision_function(X_bs)\n",
    "            fpr, tpr, thresholds = roc_curve(y_bs, y_test_score)\n",
    "            roc_auc.append(auc(fpr, tpr))\n",
    "        except AttributeError as e:\n",
    "            roc_auc.append(-1)\n",
    "\n",
    "        y_pred = model.predict(X_bs)\n",
    "        recall.append(recall_score(y_bs, y_pred))\n",
    "        precision.append(precision_score(y_bs, y_pred))\n",
    "        accuracy.append(accuracy_score(y_bs, y_pred)) \n",
    "        \n",
    "    return {\n",
    "        \"auc\": CI(roc_auc),\n",
    "        \"recall\": CI(recall),\n",
    "        \"precision\": CI(precision),\n",
    "        \"accuracy\": CI(accuracy)\n",
    "    }\n",
    "\n",
    "def compute_metrics_dl(model, X, y, k=100):\n",
    "    roc_auc = []\n",
    "    recall = []\n",
    "    precision = []\n",
    "    accuracy = []\n",
    "    for _ in range(k):\n",
    "        X_bs, y_bs = resample(X, y, replace=True)\n",
    "        evaluation = model.evaluate(X_bs, y_bs, batch_size=BATCH_SIZE, verbose=2)\n",
    "        eva = dict(zip(weighted_model.metrics_names, evaluation))\n",
    "        roc_auc.append(eva[\"auc\"])\n",
    "        recall.append(eva[\"recall\"])\n",
    "        precision.append(eva[\"precision\"])\n",
    "        accuracy.append(eva[\"accuracy\"])\n",
    "    return {\n",
    "        \"auc\": CI(roc_auc),\n",
    "        \"recall\": CI(recall),\n",
    "        \"precision\": CI(precision),\n",
    "        \"accuracy\": CI(accuracy)\n",
    "    }\n",
    "        \n",
    "def plot_auc(model, X_test, y_test):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    y_test_score = model.decision_function(X_test)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_test_score)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.title(\"ROC\")\n",
    "    plt.plot(fpr, tpr, 'b', label='AUC = %0.4f' % roc_auc)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot([0,1],[0,1], 'r--')\n",
    "    plt.xlim([0, 1.0])\n",
    "    plt.ylim([0, 1.01])\n",
    "    plt.title(\"ROC for model \" + model.__class__.__name__)\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.savefig(os.path.join(OUT_PATH, \"charts\", model.__class__.__name__ + \"ROCAUC.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'../DATAFILE'\n",
    "labresult_cps_path = 'lis_cps_result_data'\n",
    "labresult_hms_path = 'lis_hms_result_data'\n",
    "# read the file of patient demographic information\n",
    "patient_info = tools.fileReader(r\"../DATAFILE\", 'patient_data')\n",
    "# read the grouped patients\n",
    "group_patient = pd.read_csv(r\"../tables/output/group_patient.csv\", index_col=0)\n",
    "\n",
    "\n",
    "# term_id mapping\n",
    "tid_desc = tools.fileReader(r'../DATAFILE', r\"iams_concept\")\n",
    "tid_to_eid = tools.fileReader(r'../DATAFILE', r'iams_entity_concept')\n",
    "\n",
    "# labresult\n",
    "usecols = [\"pseudo_patient_key\", \"reference_dtm\", \"diff_in_hour_reference_dtm\", \"result_str\", \"entity_id\", \"si_unit\", \"si_numeric\"]\n",
    "labresult_cps = tools.fileReader(file_path, labresult_cps_path, usecols=usecols)\n",
    "labresult_hms = tools.fileReader(file_path, labresult_hms_path, usecols=usecols)\n",
    "labresult = pd.concat([labresult_cps, labresult_hms])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = group_patient\n",
    "right = patient_info[[\"pseudo_patient_key\", \"dob_Y\", \"sex\", \"death_date_Y\", \"diff_in_hour_death_date\"]]\n",
    "diab_patients_info = pd.merge(left=left, right=right, how='left', on='pseudo_patient_key')\n",
    "\n",
    "# replace null value to np.nan\n",
    "diab_patient_age = diab_patients_info.replace(r'\"\"', np.nan)\n",
    "# map the date time fieds into age inplace\n",
    "map_age(diab_patient_age, [\"pre_dtm\", \"diab_dtm\", \"death_date_Y\"])\n",
    "# convert to year of birth\n",
    "diab_patient_age[\"dob_Y\"] = diab_patient_age[\"dob_Y\"].apply(lambda x : x[:4]).astype(\"int\")\n",
    "# compute the progression period in hours\n",
    "diab_patient_age[\"prog_pd\"] = diab_patient_age[\"diab_diff_hour\"] - diab_patient_age[\"pre_diff_hour\"] \n",
    "diab_patient_age[\"diff_in_hour_death_date\"] = diab_patient_age[\"diff_in_hour_death_date\"].astype(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "from typing import List\n",
    "class LogMetrics:\n",
    "    auc: List[float]\n",
    "    recall: List[float]\n",
    "    precision: List[float]\n",
    "    accuracy: List[float]\n",
    "    \n",
    "    def __init__(self):\n",
    "        auc = []\n",
    "        recall = []\n",
    "        precision = []\n",
    "        accuracy = []\n",
    "        \n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            \"auc\": self.auc,\n",
    "            \"recall\": self.recall,\n",
    "            \"precision\": self.precision,\n",
    "            \"accuracy\": self.accuracy\n",
    "        }\n",
    "\n",
    "def parse_log(logs):\n",
    "    \n",
    "    mls = [\"logreg_info\", \"dt_info\", \"rf_info\", \"adb_info\", \"logreg_info\", \"xgb_info\", \"dl_info\"]\n",
    "    ml_metrics = {}\n",
    "    for ml in mls:\n",
    "        ml_metrics[ml] = LogMetrics()\n",
    "    \n",
    "    for info in logs:\n",
    "        for ml, metrics in ml_metrics.items():\n",
    "            if ml != \"dl_info\":\n",
    "                metrics.auc.append(logs[\"ml_info\"][\"ml\"][\"metrics\"][\"auc\"])\n",
    "                metrics.recall.append(logs[\"ml_info\"][\"ml\"][\"metrics\"][\"recall\"])\n",
    "                metrics.precision.append(logs[\"ml_info\"][\"ml\"][\"metrics\"][\"precision\"])\n",
    "                metrics.accuracy.append(logs[\"ml_info\"][\"ml\"][\"metrics\"][\"accuracy\"])\n",
    "            else:\n",
    "                metrics.auc.append(logs[ml][\"acu\"])\n",
    "                metrics.recall.append(logs[ml][\"recall\"])\n",
    "                metrics.precision.append(logs[ml][\"precision\"])\n",
    "                metrics.accuracy.append(logs[ml][\"accuracy\"])\n",
    "    return ml_metrics\n",
    "\n",
    "def CI(samples, alpha = 0.95):\n",
    "    left, right = st.norm.interval(alpha = alpha, loc = np.mean(samples), scale = st.sem(np.array(samples)))\n",
    "    return [left, (left + right) / 2, right]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in [2, 5, 10]:\n",
    "    \n",
    "    TIME_SPEC = t\n",
    "    YEAR = 2019 - TIME_SPEC\n",
    "    CUT_OFF = '{year}-12-31'.format(year=YEAR)\n",
    "    colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "    mpl.rcParams['figure.figsize'] = (12,10)\n",
    "    OUT_PATH = os.path.join(f\"../output/george/spec-{TIME_SPEC}year\")\n",
    "    PERIOD_LONG = TIME_SPEC * 365.25 * 24\n",
    "\n",
    "    #clean the directory\n",
    "    files = glob.glob('../output/george/spec-{}year/**/*.*'.format(t), recursive=True)\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "    log = {}\n",
    "    ############################################################cleaning################################################\n",
    "    # replace null value to np.nan\n",
    "\n",
    "    # exclusion\n",
    "    diab_patient_excluded = diab_patient_age.copy() # create a new reference\n",
    "    patient_num = {}\n",
    "    def show_num():\n",
    "        return [diab_patient_excluded.shape[0],\\\n",
    "                diab_patient_excluded.query(\"label == 0\").shape[0],\\\n",
    "                diab_patient_excluded.query(\"label == 1\").shape[0]\n",
    "               ] \n",
    "\n",
    "    patient_num[\"No_filtering\"] = show_num()\n",
    "\n",
    "    # Enrolment in the first year and last three year (pre_dtm > 2003-12-31 and pre_dtm <= 2014-12-31)\n",
    "    diab_patient_excluded = diab_patient_excluded.query(f\"pre_dtm <= '{CUT_OFF}' or label == 2\")\n",
    "    patient_num[\"cutoff_filtering\"] = show_num()\n",
    "\n",
    "    # Follow up time is less than {{TIME_SPEC}}\n",
    "    death_diff_hour = TIME_SPEC * 365.25 * 24\n",
    "    diab_patient_excluded = diab_patient_excluded.query(f\"diff_in_hour_death_date.isnull() or diff_in_hour_death_date - pre_diff_hour > {death_diff_hour} \\\n",
    "or label > 0\", engine='python')\n",
    "    patient_num[\"death_filtering\"] = show_num()\n",
    "\n",
    "    # Diabetes only.\n",
    "    diab_patient_excluded = diab_patient_excluded.query(\"label < 2\")\n",
    "    patient_num[\"diabonly_filtering\"] = show_num()\n",
    "\n",
    "    # Patients younger than 18(pre_age < 18)\n",
    "    diab_patient_excluded = diab_patient_excluded.query(\"pre_age >= 18\")\n",
    "    patient_num[\"age_filtering\"] = show_num()\n",
    "\n",
    "    log[\"patient_num\"] = patient_num\n",
    "    # # Follow-up time less than 1 month i.e. 30.5*24 hours\n",
    "    # diab_patient_age = diab_patient_age.query(f\"prog_pd > {MIN_FT} | prog_pd.isnull()\", engine='python')\n",
    "    diab_patient_excluded[\"cls\"] = diab_patient_excluded[\"prog_pd\"].apply(cls_mapper, PERIOD_LONG =PERIOD_LONG)\n",
    "    diab_patient_excluded.to_csv(f\"../tables/output/diab_patient-{TIME_SPEC}year.csv\")\n",
    "#     diab_patient_excluded = pd.read_csv(f\"../tables/output/diab_patient-{TIME_SPEC}year.csv\", index_col=0)\n",
    "    ############################################################plot###########################################################\n",
    "    # patient number of each group\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    count = diab_patient_excluded.groupby(\"label\")[\"label\"].count()\n",
    "    group = [\"pre-diabetes only\", \"pre-diabetes to diabetes\"]\n",
    "    bar_color = ['tab:red', 'tab:blue']\n",
    "    ax.bar(group, count, label = group, color = bar_color)\n",
    "    ax.set_ylabel(\"patients number\")\n",
    "    ax.set_title(\"patients number of each group\")\n",
    "    for i, v in enumerate(count.to_list()):\n",
    "        plt.text(i, v, \"{:,}\".format(v), ha = 'center')\n",
    "    plt.savefig(os.path.join(OUT_PATH, \"charts\", \"patients_number.png\"))\n",
    "\n",
    "    death = diab_patient_excluded[diab_patient_age.death_age.notnull()]\n",
    "    pre = diab_patient_excluded[diab_patient_age.label == 0]\n",
    "    pre2diab = diab_patient_excluded[diab_patient_age.label == 1]\n",
    "    diab = diab_patient_excluded[diab_patient_age.label == 2]\n",
    "\n",
    "    # death number of each group\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    count = death.groupby(\"label\")[\"label\"].count()\n",
    "    group = [\"pre-diabetes only\", \"pre-diabetes to diabetes\"]\n",
    "    bar_color = ['tab:green', 'tab:purple', 'tab:pink']\n",
    "    ax.bar(group, count, label = group, color = bar_color)\n",
    "    ax.set_ylabel(\"patients number\")\n",
    "    ax.set_title(\"death number of each class\")\n",
    "    for i, v in enumerate(count.to_list()):\n",
    "        plt.text(i, v, \"{:,}\".format(v), ha = 'center')\n",
    "    plt.savefig(os.path.join(OUT_PATH,\"charts\", \"death_class.png\"))\n",
    "\n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "    \n",
    "    # prediabetes distribution against age\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    bin = pd.cut(pre.pre_age, bins=[5 * (i) for i in range(3,23)])\n",
    "    out = bin.value_counts(sort=False)\n",
    "    ax = out.plot.bar(rot=30, color='b', figsize=(8,4))\n",
    "    ax.set_xticklabels([\"18-20\"] + [f\"{i*5}-{i*5+5}\" for i in range(4, 22)])\n",
    "    ax.set_xlabel(\"Age\")\n",
    "    ax.set_ylabel(\"Number\")\n",
    "    _ = ax.set_title(\"Distribution of prediabetes against age\")\n",
    "    plt.savefig(os.path.join(OUT_PATH, \"charts\", \"distribution_pre_age.png\"))\n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "    \n",
    "    # distribution of pre to diabetes patients for the baseline cohort\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    bin = pd.cut(pre2diab.pre_age, bins=[5 * (i) for i in range(3,23)])\n",
    "    out = bin.value_counts(sort=False)\n",
    "    out.to_csv(os.path.join(OUT_PATH,\"charts\", \"distribution_pre2diab_age.csv\"))\n",
    "    ax = out.plot.bar(rot=30, color='b', figsize=(8,4))\n",
    "    ax.set_xticklabels([\"18-20\"] + [f\"{i*5}-{i*5+5}\" for i in range(4, 22)])\n",
    "    ax.set_xlabel(\"Age\")\n",
    "    ax.set_ylabel(\"Number\")\n",
    "    _ = ax.set_title(\"Distribution of prediabetes against age\")\n",
    "    plt.savefig(os.path.join(OUT_PATH, \"charts\", \"distribution_pre2diab_age.png\"))\n",
    "\n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "    \n",
    "    # patient portion\n",
    "    temp = diab_patient_excluded.assign(pre_year = diab_patient_age[\"pre_dtm\"].apply(lambda s : str(s)[:4]))\n",
    "    idx_to_dx = {0: \"No T2DM Incidence\", 1: \"With T2DM Incidence\"}\n",
    "    temp[\"Label\"] = temp[\"cls\"].apply(lambda x : idx_to_dx[x])\n",
    "    temp_group = temp.groupby([\"pre_year\", \"Label\"]).size().unstack()\n",
    "    percent = (temp_group[\"With T2DM Incidence\"] / (temp_group[\"With T2DM Incidence\"] + temp_group[\"No T2DM Incidence\"])) * 100\n",
    "    ax = temp_group.plot(kind=\"bar\", stacked=True, colormap=\"Set2\", figsize=(8,5))\n",
    "    mid = temp_group[\"With T2DM Incidence\"] / 2 + temp_group[\"No T2DM Incidence\"]\n",
    "    for con in ax.containers:\n",
    "        plt.setp(con, width=0.5)\n",
    "    x0, x1 = ax.get_xlim()\n",
    "    ax.set_xlim(x0-1, x1+1)\n",
    "    for i,per in enumerate(percent):\n",
    "        plt.text(i, mid[i], str(np.round(per,1)) + '%', va='center', ha='center')\n",
    "    ax.set_ylabel(\"Number of patients\")\n",
    "    ax.set_xlabel(\"Year of confirming prediabetes\")\n",
    "    _ = ax.set_title(\"Patients of different class portion against prediabetes confirmation time(year)\")\n",
    "    temp_group[\"incidence_rate\"] = percent\n",
    "    temp_group.to_csv(os.path.join(OUT_PATH,\"charts\", \"patient_portion_each_class.csv\"))\n",
    "    plt.savefig(os.path.join(OUT_PATH,\"charts\", \"patient_portion_each_class.png\"))\n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "    \n",
    "#     # T2DM progression survival curve\n",
    "#     years = [f'{x}-01-01' for x in range(2004,2018)]\n",
    "#     cnt = []\n",
    "#     INTV = 1\n",
    "#     age = [INTV*i for i in range(20//INTV,90//INTV + 1)]\n",
    "#     for a in age:\n",
    "#         cnt.append(diab_patient_age.query(f\"diab_age < {a} and not (death_age < {a})\")[\"pseudo_patient_key\"].count())\n",
    "#     surv = [diab_patient_age.shape[0] - c for c in cnt]\n",
    "#     fig, ax = plt.subplots(figsize=(10,5))\n",
    "#     ax.step(age, surv, 'k-', color='r')\n",
    "#     ax.set_xticks([5*i for i in range(4, 19)])\n",
    "#     ax.tick_params(axis='x', labelrotation=45)\n",
    "#     ax.set_xlabel(\"Prediabetes age\")\n",
    "#     ax.set_ylabel(\"Number of patients\")\n",
    "#     _ = ax.set_title(\"T2DM progression survival curve\")\n",
    "#     plt.savefig(os.path.join(OUT_PATH,\"charts\", \"survival_curve.png\"))\n",
    "#     plt.cla()\n",
    "#     plt.clf()\n",
    "    \n",
    "    # investigate the progress free period against the age\n",
    "    data = pre2diab.assign(period = pre2diab.diab_age - pre2diab.pre_age)[[\"pre_age\", \"diab_age\", \"death_age\", \"period\"]]\n",
    "    bin = pd.cut(data.pre_age, bins = [5 * i for i in range(3,23)])\n",
    "    data = data.assign(bin = bin)\n",
    "    out = data.groupby(\"bin\").agg({\"period\":[\"count\",\"mean\"]})\n",
    "    out.to_csv(os.path.join(OUT_PATH,\"charts\", \"progress_free_period.csv\"))\n",
    "    ###################### plot ##########################\n",
    "    ax = out[\"period\"][\"mean\"].plot.bar(rot=30, color='b', figsize=(10,4))\n",
    "    ax.plot([\"18-20\"] + [f\"{i*5}-{i*5+5}\" for i in range(4, 22)],out[\"period\"][\"mean\"].tolist())\n",
    "    ax.set_xticklabels([\"18-20\"] + [f\"{i*5}-{i*5+5}\" for i in range(4, 22)])\n",
    "    ax.set_xlabel(\"Age\")\n",
    "    ax.set_ylabel(\"Year\")\n",
    "    ax.set_ylim([0,6])\n",
    "    _ = ax.set_title(\"Mean progression period with respect to prediabetes age\")\n",
    "    # write to disk\n",
    "    plt.savefig(os.path.join(OUT_PATH,\"charts\", \"progress_free_period.png\"))\n",
    "    out.to_csv(os.path.join(OUT_PATH,\"charts\", \"progress_free_period.csv\"))\n",
    "    log[\"mean_progression_year\"] = data[\"period\"].mean()\n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "    \n",
    "    ##########################################################analysis###########################################################\n",
    "\n",
    "    target_id = pd.Series(term_id).rename('term_id')\n",
    "    patients = diab_patient_excluded\n",
    "    target_tid_mapping = pd.merge(target_id,tid_to_eid,how='left',on='term_id')\n",
    "    labresult_filtered = pd.merge(labresult,target_tid_mapping,how='inner',on='entity_id')\n",
    "    #replace the null value with np.nan\n",
    "    labresult_filtered.replace(r'\"\"', np.nan, inplace=True)\n",
    "    #left join the patients tables and test tables\n",
    "    patients_test = pd.merge(left=patients[[\"pseudo_patient_key\", \"pre_diff_hour\", \"diab_diff_hour\"]], \n",
    "                             right=labresult_filtered[[\"pseudo_patient_key\", \"term_id\", \"reference_dtm\", \"diff_in_hour_reference_dtm\", \"si_unit\",\"si_numeric\" ]], \n",
    "                             on=\"pseudo_patient_key\", \n",
    "                             how=\"left\")\n",
    "    #rename\n",
    "    patients_test.rename(columns = {\"diff_in_hour_reference_dtm\": \"test_diff_hour\", \"reference_dtm\": \"test_dtm\"}, inplace=True)\n",
    "    # select the observations that the test is within six month before the \n",
    "    # prediabetes diagnosis to three months after\n",
    "    # patients_test_filtered = patients_test.query(\"test_diff_hour > (pre_diff_hour - 6 * 30 * 24) and test_diff_hour < (pre_diff_hour + 3 * 60 * 24)\")\n",
    "    patients_test_filtered = patients_test.query(\"test_diff_hour <= pre_diff_hour and test_diff_hour > (pre_diff_hour - 6 * 30 * 24)\")\n",
    "    # drop the observations that the test is later than diagnosis of diabetes\n",
    "    # patients_test_filtered = patients_test_filtered.query(\"diab_diff_hour.isnull() or test_diff_hour < diab_diff_hour\", engine=\"python\")\n",
    "\n",
    "    # only keep the patient id, term_id and test results\n",
    "    patients_test_filtered = patients_test_filtered[[\"pseudo_patient_key\", \"term_id\", \"test_diff_hour\", \"si_numeric\"]]\n",
    "    # casting type for si_numeric\n",
    "    patients_test_filtered[\"si_numeric\"] = patients_test_filtered[\"si_numeric\"].astype(\"float\")\n",
    "    patients_test_group = patients_test_filtered\\\n",
    "    .sort_values(by=[\"pseudo_patient_key\", \"test_diff_hour\"])\\\n",
    "    .groupby([\"pseudo_patient_key\", \"term_id\"], as_index=False)\\\n",
    "    .agg({\"si_numeric\":\"mean\"})\n",
    "    patients_features_pivoted = patients_test_group.pivot_table(index=\"pseudo_patient_key\", columns=\"term_id\", values=\"si_numeric\")\n",
    "    # reset index\n",
    "    patients_features_pivoted = patients_features_pivoted.reset_index()\n",
    "    # rename all the tests out of interest\n",
    "    patients_features_pivoted.rename(columns=name_dict, inplace=True)\n",
    "    dataset = pd.merge(left=patients_features_pivoted, right=patients, how=\"inner\", on=\"pseudo_patient_key\") # join the with the patient information\n",
    "    dataset = dataset.query(\"HBA1C < 6.4 or HBA1C.isnull()\", engine='python')\n",
    "    dataset = dataset.query(\"cholesLDL_1 > 0 or cholesLDL_1.isnull()\", engine='python')\n",
    "    dataset.to_csv(f\"../tables/output/dataset-{TIME_SPEC}year\")\n",
    "    \n",
    "    # plot feature distribution\n",
    "    def plot_feature_cpf(feature_name:str):\n",
    "        y, x, _ = plt.hist(dataset[feature_name], ec=\"black\", bins=500, cumulative=-1, histtype=\"step\", density=True)\n",
    "        pd.DataFrame({\"x\": x[1:], \"y\": y}).to_csv(os.path.join(OUT_PATH, \"charts\", \"baseline_{}_dist.csv\".format(feature_name)))\n",
    "        plt.savefig(os.path.join(OUT_PATH, \"charts\", \"baseline_{}_dist.png\".format(feature_name)))\n",
    "        plt.cla()\n",
    "        plt.clf()\n",
    "    \n",
    "        \n",
    "    \n",
    "    mean = []\n",
    "    std = []\n",
    "    iqr = []\n",
    "    mad = []\n",
    "    missing_rate = []\n",
    "    pvalue = []\n",
    "    indicators = [\"pre_age\", \"sex\"] + list(name_dict.values())\n",
    "    pos_mean = []\n",
    "    neg_mean = []\n",
    "    pos_std = []\n",
    "    neg_std = []\n",
    "    pos_iqr = []\n",
    "    neg_iqr = []\n",
    "    pos_mad = []\n",
    "    neg_mad = []\n",
    "    \n",
    "    for ind in indicators:\n",
    "        if ind == \"sex\":\n",
    "            temp = dataset[['sex', 'cls']]\n",
    "            male_0 = temp.query(\"sex == 'M' and cls == 0\").count()\n",
    "            male_1 = temp.query(\"sex == 'M' and cls == 1\").count()\n",
    "            female_0 = temp.query(\"sex == 'F' and cls == 0\").count()\n",
    "            female_1 = temp.query(\"sex == 'F' and cls == 1\").count()\n",
    "            result = stats.chi2_contingency([[male_0, female_0], [male_1, female_1]])\n",
    "            p_value = result[1]\n",
    "            pvalue.append(p_value)\n",
    "            mean.append(np.nan)\n",
    "            std.append(np.nan)\n",
    "            iqr.append(np.nan)\n",
    "#             mad.append(np.nan)\n",
    "            pos_mean.append(np.nan)\n",
    "            neg_mean.append(np.nan)\n",
    "            pos_std.append(np.nan)\n",
    "            neg_std.append(np.nan)\n",
    "            pos_iqr.append(np.nan)\n",
    "            neg_iqr.append(np.nan)\n",
    "#             pos_mad.append(np.nan)\n",
    "#             neg_mad.append(np.nan)\n",
    "        else:\n",
    "            temp = dataset[[ind, \"cls\"]]\n",
    "            temp = temp[temp[ind].notnull()]\n",
    "            t0 = temp.query(\"cls == 0\")[ind]\n",
    "            t1 = temp.query(\"cls == 1\")[ind]\n",
    "            result = stats.ttest_ind(t0, t1)\n",
    "            pvalue.append(result.pvalue)\n",
    "            mean.append(temp[ind].mean())\n",
    "            std.append(temp[ind].std())\n",
    "            iqr.append(stats.iqr(temp[ind]))\n",
    "#             mad.append(stats.median_abs_deviation(temp[ind]))\n",
    "            pos_mean.append(t1.mean())\n",
    "            neg_mean.append(t0.mean())\n",
    "            pos_std.append(t1.std())\n",
    "            neg_std.append(t0.std())\n",
    "            neg_iqr.append(stats.iqr(t0))\n",
    "            pos_iqr.append(stats.iqr(t1))\n",
    "#             pos_mad.append(stats.median_abs_deviation(t1))\n",
    "#             neg_mad.append(stats.median_abs_deviation(t0))\n",
    "            plot_feature_cpf(ind)\n",
    "            \n",
    "    stt = pd.DataFrame({\n",
    "        \"feauture\": indicators,\n",
    "        \"mean\": mean,\n",
    "        \"standard deviance\": std,\n",
    "        \"iqr\": iqr,\n",
    "#         \"mad\": mad,\n",
    "        \"neg_mean\": neg_mean,\n",
    "        \"neg_std\": neg_std,\n",
    "        \"neg_iqr\": neg_iqr,\n",
    "#         \"neg_mad\": neg_mad,\n",
    "        \"pos_mean\": pos_mean,\n",
    "        \"pos_std\": pos_std,\n",
    "        \"pos_iqr\": pos_iqr,\n",
    "#         \"pos_mad\": pos_mad,\n",
    "        \"p-value\": pvalue\n",
    "    })\n",
    "\n",
    "    demo_info =['pseudo_patient_key',\n",
    "            'pre_dtm', \n",
    "            'pre_diff_hour', \n",
    "            'sex',\n",
    "            'pre_age',\n",
    "           'cls']\n",
    "    # select missingness less than 30% tets and HBA1C\n",
    "\n",
    "    tests_name = list(name_dict.values())\n",
    "    features = dataset.copy()[demo_info+tests_name]\n",
    "    missing = features.isnull().sum()\n",
    "    percent = features.isnull().sum() / features.isnull().count()\n",
    "    valid = features.notnull().sum()\n",
    "    missing_data = pd.concat([missing, valid,percent], axis=1, keys=[\"Missing\",\"Valid\", \"Missing_percent\"])\n",
    "    missing_data.sort_values(\"Missing_percent\")\n",
    "    # add to statistic result dataframe\n",
    "    stt[\"Missing Rate\"] = missing_data.loc[indicators, \"Missing_percent\"].to_list()\n",
    "\n",
    "    # write to disk\n",
    "    stt.to_csv(os.path.join(OUT_PATH, \"tables\", \"overall_statistics.csv\"))\n",
    "    valid_tests = missing_data.loc[tests_name].query(\"Missing_percent < 0.3\").index.to_list()\n",
    "\n",
    "    if not 'HBA1C' in valid_tests:\n",
    "        valid_tests.append('HBA1C')\n",
    "\n",
    "    ds = dataset.copy()[demo_info + valid_tests]\n",
    "    # drop all the missing data\n",
    "    ds = ds.dropna(how=\"any\")\n",
    "    sex_mapper = {'F':0, 'M':1}\n",
    "    ds[\"sex\"] = ds[\"sex\"].apply(lambda x : sex_mapper[x])\n",
    "    df_train, df_test = train_test_split(ds, test_size=0.1, random_state=42)\n",
    "\n",
    "    # normalize the data using RobustScaler()\n",
    "    scaler = RobustScaler()\n",
    "    df_train[valid_tests] = scaler.fit_transform(df_train[valid_tests])\n",
    "    df_test[valid_tests] = scaler.transform(df_test[valid_tests])\n",
    "    # write to disk\n",
    "    df_train.describe().to_csv(os.path.join(OUT_PATH, \"tables\", \"training_data_desc.csv\"))\n",
    "    df_test.describe().to_csv(os.path.join(OUT_PATH, \"tables\", \"test_data_desc.csv\"))\n",
    "    # save the scaler\n",
    "    file = os.path.join(OUT_PATH, \"models\", \"scaler.pkl\")\n",
    "    pickle.dump(scaler, open(file, 'wb'))\n",
    "\n",
    "    X_train = df_train[valid_tests + [\"pre_age\", \"sex\"]]\n",
    "    y_train = df_train[\"cls\"]\n",
    "    X_test = df_test[valid_tests + [\"pre_age\", \"sex\"]]\n",
    "    y_test = df_test[\"cls\"]\n",
    "\n",
    "    #######################################################feature selection#########################################\n",
    "    fs_conf = {}\n",
    "    lr = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "    grid = {\"C\": [0.001, 0.01, 0.1, 1, 10 ,100, 1000]}\n",
    "    search = GridSearchCV(estimator=lr, param_grid=grid)\n",
    "    search.fit(X_train, y_train)\n",
    "    fs_conf[\"C\"] = search.best_params_[\"C\"]\n",
    "    features = np.array(X_train.columns).reshape(1,-1)\n",
    "    gs_model = LogisticRegression(**search.best_params_, penalty='l1', solver='liblinear')\n",
    "    gs_model.fit(X_train, y_train)\n",
    "    coefficients = gs_model.coef_\n",
    "    importance = np.abs(coefficients)\n",
    "\n",
    "    valid_features=features[importance>0]\n",
    "\n",
    "    fs_conf[\"valid_features\"] = list(valid_features)\n",
    "    log[\"feature_selection\"] = fs_conf\n",
    "\n",
    "    # oversample\n",
    "    ros = RandomOverSampler(random_state=0)\n",
    "    X_train, y_train = ros.fit_resample(X_train, y_train)\n",
    "    dataset = {\n",
    "        \"training_size\": X_train.shape[0],\n",
    "        \"test_size\": X_test.shape[0],\n",
    "        \"positive_rate\": y_test.mean()\n",
    "    }\n",
    "    log[\"dataset\"] = dataset\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##################################################Machine Learning Model###################################################\n",
    "    ml_info={}\n",
    "\n",
    "    ##### Logistic regression ########\n",
    "    logreg_info = {}\n",
    "    logreg = LogisticRegression()\n",
    "\n",
    "    grid = {\"C\": [0.001, 0.01, 0.1, 1, 10 ,100, 1000], 'penalty':['l1', 'l2']}\n",
    "\n",
    "    logreg_cv = GridSearchCV(logreg, grid, cv=5, scoring='balanced_accuracy')\n",
    "    logreg_cv.fit(X_train, y_train)\n",
    "    print(\"Best parameters \" , logreg_cv.best_params_)\n",
    "    logreg2 = LogisticRegression(**logreg_cv.best_params_)\n",
    "    logreg2.fit(X_train, y_train)\n",
    "    logreg_info[\"parametes\"] = logreg_cv.best_params_\n",
    "    logreg_info[\"evaluation\"] = compute_metrics(logreg2, X_test, y_test)\n",
    "    plot_auc(logreg2, X_test, y_test)\n",
    "    ml_info[\"logreg_info\"] = logreg_info\n",
    "    # write to disk\n",
    "    file = os.path.join(OUT_PATH, \"models\", \"logreg.pkl\")\n",
    "    pickle.dump(logreg2, open(file, 'wb'))\n",
    "    ##### Decision tree ##############\n",
    "    dt_info = {}\n",
    "    dt = DecisionTreeClassifier()\n",
    "    dt.fit(X_train, y_train)\n",
    "    dt_info[\"evaluation\"] = compute_metrics(dt, X_test, y_test)\n",
    "    ml_info[\"dt_info\"] = dt_info\n",
    "    # write to disk\n",
    "    file = os.path.join(OUT_PATH, \"models\", \"dt.pkl\")\n",
    "    pickle.dump(dt, open(file, 'wb'))\n",
    "    ##########Random Forest ##############\n",
    "    rf_info = {}\n",
    "    rfc = RandomForestClassifier(class_weight={0.0:1,1.0:3}, random_state=42)\n",
    "    rfc.fit(X_train, y_train)\n",
    "    rf_info[\"evaluation\"] = compute_metrics(rfc, X_test, y_test)\n",
    "    rf_info[\"configuration\"] = {\"weight\": {0:1,1:3}}\n",
    "    ml_info[\"rf_info\"] = rf_info\n",
    "    # write to disk\n",
    "    file = os.path.join(OUT_PATH, \"models\", \"rf.pkl\")\n",
    "    pickle.dump(rfc, open(file, 'wb'))\n",
    "    #######Adaboost Classifier###########\n",
    "    adb_info = {}\n",
    "    adb = AdaBoostClassifier(n_estimators=100)\n",
    "    adb.fit(X_train, y_train)\n",
    "    adb_info[\"configuration\"] = {\n",
    "        \"n_estimators\": 100\n",
    "    }\n",
    "    adb_info[\"evaluation\"] = compute_metrics(adb, X_test, y_test)\n",
    "    plot_auc(adb, X_test, y_test)\n",
    "    ml_info[\"adb_info\"] = adb_info\n",
    "    # write to disk\n",
    "    file = os.path.join(OUT_PATH, \"models\", \"adb.pkl\")\n",
    "    pickle.dump(adb, open(file, 'wb'))\n",
    "    ##########Gradient Boosting Classifier###########           \n",
    "    xgb_info = {}\n",
    "    xgb= GradientBoostingClassifier(n_estimators=100, max_depth=1, random_state=42).fit(X_train, y_train)\n",
    "    xgb_info[\"configuration\"] = {\n",
    "        \"n_estimators\":100,\n",
    "        \"max_depth\": 1\n",
    "    }\n",
    "    xgb_info[\"evaluation\"] = compute_metrics(xgb, X_test, y_test)\n",
    "    plot_auc(xgb, X_test, y_test)\n",
    "    ml_info[\"xgb_info\"] = xgb_info\n",
    "    # write to disk\n",
    "    file = os.path.join(OUT_PATH, \"models\", \"xgb.pkl\")\n",
    "    pickle.dump(xgb, open(file, 'wb'))\n",
    "    ###################SVM#############################\n",
    "    # SVM_info = {}\n",
    "    # SVM = SVC(gamma=\"auto\").fit(X_train, y_train)\n",
    "    # SVM_info[\"configuration\"] = {\"kernel\": \"rbf\"}\n",
    "    # SVM_info[\"evaluation\"] = get_scores(SVM)\n",
    "    # ml_info[\"SVM_info\"] = SVM_info\n",
    "\n",
    "    log[\"ml_info\"] = ml_info\n",
    "    ##################################################Deep Learning Model###################################################\n",
    "    # early stopping callback on AUC\n",
    "    dl_info = {}\n",
    "    EPOCHS = 100\n",
    "    BATCH_SIZE = 2000 # make sure each batch containes positive cases\n",
    "    callbacks: AUCStopping = AUCStopping()\n",
    "\n",
    "\n",
    "    weighted_model = make_model(X_train)\n",
    "    class_weight = {0: 1, 1: 1.5}\n",
    "    weighted_history = weighted_model.fit(\n",
    "        X_train,\n",
    "        y_train.astype(np.int64),\n",
    "        batch_size=100,\n",
    "        epochs=100,\n",
    "        validation_data=(X_test, y_test),\n",
    "        callbacks = [callbacks],\n",
    "        class_weight=class_weight\n",
    "    )\n",
    "    weighted_model.save(os.path.join(OUT_PATH,\"models\", \"weighted_model\"))\n",
    "    model_conf = {}\n",
    "    model_conf[\"epochs\"] = EPOCHS\n",
    "    model_conf[\"BATCH_SIZE\"] = BATCH_SIZE\n",
    "    model_conf[\"weight\"] = class_weight\n",
    "    dl_info[\"model_conf\"] = model_conf\n",
    "    dl_info[\"evaluation\"] = compute_metrics_dl(weighted_model, X_test, y_test)\n",
    "    log[\"dl_info\"] = dl_info\n",
    "\n",
    "    #################feature importance##########\n",
    "    imp = permutation_importance(weighted_model, X_test, y_test, 30, roc_auc_score, average=\"weighted\")\n",
    "    log[\"feature_importance\"] = imp\n",
    "\n",
    "    #################plot########################\n",
    "    colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "    mpl.rcParams['figure.figsize'] = (12,10)\n",
    "    train_predictions_weighted = weighted_model.predict(X_train, batch_size=BATCH_SIZE)\n",
    "    test_predictions_weighted = weighted_model.predict(X_test, batch_size=BATCH_SIZE)\n",
    "\n",
    "    plot_metrics(weighted_history)\n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "\n",
    "    #####################################################PLOT ROC#############################\n",
    "    _ = plot_roc(\"Train Weighted\", y_train, train_predictions_weighted, color=colors[0], linestyle='--')\n",
    "    fp, tp, threshold = plot_roc(\"Test Weighted\", y_test, test_predictions_weighted, color=colors[1], linestyle='--')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(os.path.join(OUT_PATH, \"charts\", \"Model ROC\"))\n",
    "\n",
    "\n",
    "    # get optimal threshold\n",
    "    gmean = np.sqrt(tp * (1-fp))\n",
    "    index = np.argmax(gmean)\n",
    "    threshold_op = round(threshold[index], ndigits=4)\n",
    "    fp_op = round(fp[index], ndigits=4)\n",
    "    tp_op = round(tp[index], ndigits=4)\n",
    "    pos_sample = test_predictions_weighted[y_test == 1]\n",
    "    pos_dist = pd.DataFrame(pos_sample).describe()\n",
    "    log[\"threshold\"] = float(threshold_op)\n",
    "\n",
    "    ## plot confusion matrix\n",
    "    plot_cm(y_test, weighted_model.predict(X_test), name=\"Weighted Neural Network Confusion Matrix\")\n",
    "#     X_test_valid = X_test[y_test == 1]\n",
    "    X_test_valid = X_test\n",
    "    pred_series_valid = weighted_model.predict(X_test_valid)\n",
    "    pred_series_valid = pd.Series(pred_series_valid[:,0])\n",
    "    density = stats.gaussian_kde(pred_series_valid)\n",
    "    x = np.linspace(0,1,100)\n",
    "    d = density(x)\n",
    "    log[\"density\"] = d.tolist()\n",
    "    log[\"risk_level\"] = [pos_dist.loc[\"25%\"][0], pos_dist.loc[\"50%\"][0], pos_dist.loc[\"75%\"][0]]\n",
    "    json_log = json.dumps(log)\n",
    "    with open(os.path.join(OUT_PATH, \"result.json\"), 'w', encoding='utf-8')as f:\n",
    "        json.dump(json_log, f, ensure_ascii=False, indent=4)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
