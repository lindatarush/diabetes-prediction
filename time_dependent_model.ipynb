{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import util.cleaning_tools as tools\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay,\\\n",
    "precision_recall_curve, auc, roc_auc_score, roc_curve, recall_score\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2,f_regression\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "\n",
    "from random import sample\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_dict = {\n",
    "    5200279: \"creatinineRenal\",\n",
    "    5200289: \"cholesHDL\",\n",
    "    5200290: \"choles\",\n",
    "    5200295: \"creatinine\",\n",
    "    5200305: \"glucose\",\n",
    "    5200306: \"fastingGlucose\",\n",
    "    5200325: \"triglyceride\",\n",
    "    5200406: \"cholesLDL_1\",\n",
    "    5201215: \"glucoseInBlood\",\n",
    "    5203289: \"proteinCreatinineRatio\" ,   \n",
    "    5200345: \"albumin\",\n",
    "    5200346: \"albumin24h\",\n",
    "    5200387: \"potassiumSerumOrPlasma\",\n",
    "    5200393: \"proteinUrine\",\n",
    "    5200394: \"proteinUrine24h\",\n",
    "    5200402: \"albuminCreatinineRatio\",\n",
    "    5200485: \"HBA1C\",\n",
    "    5200547: \"albuminUnspecifiedTime\",\n",
    "    5200679: \"cholesLDL_2\",\n",
    "    5200715: \"creatinineRenalClearance\",\n",
    "    5200935: \"microalbuminCreatinineRatio\",\n",
    "    5201051: \"proteinCreatinineMassRatio\",\n",
    "    5204348: \"glomerularFiltrationRate\"\n",
    "}\n",
    "test = list(name_dict.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests_dict = {5200289: \"cholesHDL\",\n",
    " 5200290: \"choles\",\n",
    " 5200295: \"creatinine\",\n",
    " 5200306: \"fastingGlucose\",\n",
    " 5200325: \"triglyceride\",\n",
    " 5200485: \"HBA1C\"\n",
    "}\n",
    "tests_id = list(tests_dict.keys())\n",
    "tests_name = list(tests_dict.values())\n",
    "demo_info =['pseudo_patient_key',\n",
    "            'pre_dtm', \n",
    "            'pre_diff_hour', \n",
    "            'sex',\n",
    "            'pre_age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patients data\n",
    "patients = pd.read_csv(r'../tables/output/group_patient_age.csv', index_col=0)\n",
    "\n",
    "# define the file path and tables path for file reading\n",
    "file_path = r'../DATAFILE'\n",
    "tid_to_eid_path = r'iams_entity_concept'\n",
    "labresult_cps_path = 'lis_cps_result_data'\n",
    "labresult_hms_path = 'lis_hms_result_data'\n",
    " \n",
    "# read the fragment files and concat them\n",
    "usecols = [\"pseudo_patient_key\", \"reference_dtm\", \"diff_in_hour_reference_dtm\", \"result_str\", \"entity_id\", \"si_unit\", \"si_numeric\"]\n",
    "labresult_cps = tools.fileReader(file_path, labresult_cps_path, usecols=usecols)\n",
    "labresult_hms = tools.fileReader(file_path, labresult_hms_path, usecols=usecols)\n",
    "tid_to_eid = tools.fileReader(file_path, tid_to_eid_path)\n",
    "\n",
    "# the datafield of cps and hms are the same, so we can concate them.\n",
    "labresult = pd.concat([labresult_cps, labresult_hms])\n",
    "# delete the reference to the raw data for the sake of garbage recycling\n",
    "del labresult_cps\n",
    "del labresult_hms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tid_to_eid_path = r'iams_entity_concept'\n",
    "tid_to_eid = tools.fileReader(file_path, tid_to_eid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = patients.query(\"label != 2\")\n",
    "patients = patients.query(\"diab_age >= 18.0 or diab_age.isnull()\", engine=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eid = tid_to_eid[tid_to_eid.term_id.isin(tests_id)][\"entity_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=[\"pseudo_patient_key\", \"age\", 'sex','test_name', 'si_numeric', 'diff_in_hour_reference_dtm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left join the table with the patients test\n",
    "dataset = pd.merge(left=patients, right=labresult[labresult.entity_id.isin(eid)], how='inner', on=\"pseudo_patient_key\")\n",
    "del labresult\n",
    "# map the age\n",
    "f = lambda x : int(x[:4])\n",
    "dataset = dataset.assign(age=dataset[\"reference_dtm\"].apply(f) - dataset[\"dob_Y\"].apply(f))\n",
    "# merge with tid\n",
    "dataset = pd.merge(left=dataset, right=tid_to_eid, how='inner', on=\"entity_id\")\n",
    "# map the name of the tests\n",
    "dataset[\"test_name\"] = dataset[\"term_id\"].apply(lambda x : tests_dict[x])\n",
    "# truncate the dataset at the moment of the prediabetes\n",
    "dataset = dataset.query(\"reference_dtm <= pre_dtm\")\n",
    "# drop the patient later than 2016-12-31\n",
    "dataset = dataset.query(\"pre_dtm <= '2016-12-31'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table pivote to make sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = dataset[features]\n",
    "sex_mapper = {'F':0, 'M':1}\n",
    "ds['sex'] = ds['sex'].apply(lambda x : sex_mapper[x])\n",
    "ds = ds.replace(r'\"\"', np.nan)\n",
    "ds[\"si_numeric\"] = ds[\"si_numeric\"].astype(np.float32)\n",
    "ds = ds.pivot_table(index=[\"pseudo_patient_key\", \"age\", 'sex',\"diff_in_hour_reference_dtm\"], \n",
    "                 columns=\"test_name\", \n",
    "                 values=\"si_numeric\",\n",
    "                    fill_value = 0\n",
    "                )\n",
    "ds = ds.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right = dataset[[\"pseudo_patient_key\",\"label\"]].drop_duplicates()\n",
    "ds = pd.merge(left=ds, right=right, on=\"pseudo_patient_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# find the max length of test sequence\n",
    "MAX_LEN = 60\n",
    "# n_patient = ds.pseudo_patient_key.nunique()\n",
    "# ds = ds.sort_values([\"pseudo_patient_key\",\"age\",\"diff_in_hour_reference_dtm\"])\n",
    "\n",
    "\n",
    "patient_id = ds[\"pseudo_patient_key\"].unique()\n",
    "head = 0\n",
    "tail = 0\n",
    "n = ds.shape[0]\n",
    "def to_X(df):\n",
    "    col = [\"age\", \"sex\"]+tests_name\n",
    "    n = df.shape[0]\n",
    "    n_patient = df.pseudo_patient_key.nunique()\n",
    "    df = df.sort_values([\"pseudo_patient_key\", \"diff_in_hour_reference_dtm\"])\n",
    "    patient_id = df[\"pseudo_patient_key\"].unique()\n",
    "    X = np.zeros((n_patient, MAX_LEN, 8))\n",
    "    head = 0\n",
    "    tail = 0\n",
    "    y = np.zeros((n_patient,))\n",
    "    for i, id in enumerate(patient_id):\n",
    "        y[i] = df.iloc[tail][\"label\"]\n",
    "        while(df.iloc[tail][\"pseudo_patient_key\"] == id):\n",
    "            tail += 1\n",
    "            if tail == n:\n",
    "                break\n",
    "        diff = min(tail - head, 60)\n",
    "        X[i,:diff, :] = df.iloc[head:head+diff][col]\n",
    "        head = tail\n",
    "        if i % 1000 == 0:\n",
    "            print(f\"finished {i}/{n_patient}\")\n",
    "    return X, y\n",
    "# split the data to test and train set\n",
    "# train_df, test_df = train_test_split(X, y, test_size=0.1, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = to_X(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "    keras.metrics.TruePositives(name='tp'),\n",
    "    keras.metrics.FalsePositives(name='fp'),\n",
    "    keras.metrics.TrueNegatives(name='fn'),\n",
    "    keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "    keras.metrics.Precision(name='precision'),\n",
    "    keras.metrics.Recall(name='recall'), # we focus on recall metrics\n",
    "    keras.metrics.AUC(name='auc'),\n",
    "    keras.metrics.AUC(name='prc', curve='PR') # precision-recall curve\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "EMB_DIM = 8 # the dimension of defining the state\n",
    "LSTM1_DIM = 128\n",
    "LSTM2_DIM = 64\n",
    "model_lstm = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv1D(filters=64, kernel_size=3, strides=1, activation='relu', padding='causal', input_shape=[MAX_LEN,EMB_DIM]),\n",
    "    tf.keras.layers.LSTM(LSTM1_DIM, return_sequences=True),\n",
    "    tf.keras.layers.LSTM(LSTM2_DIM),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dropout(0.5), # avoid overfitting\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_lstm.compile(loss=keras.losses.BinaryCrossentropy(), optimizer=keras.optimizers.Adam(learning_rate=1e-4), metrics=METRICS)\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 599\n",
    "print(y[n])\n",
    "p = ds[\"pseudo_patient_key\"].unique()\n",
    "print(p[n])\n",
    "pd.DataFrame(X[n], columns=[\"age\", \"sex\"]+tests_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "weight_minor = 1\n",
    "weight_major = 10\n",
    "class_weight = {0: weight_major, 1: weight_minor}\n",
    "weighted_history = model_lstm.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=1000,\n",
    "    validation_data=(X_test, y_test),\n",
    "    class_weight=class_weight,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec = keras.metrics.Precision(name='precision')\n",
    "recall = keras.metrics.Recall(name='recall')\n",
    "auc = keras.metrics.AUC(name='auc')\n",
    "prc = keras.metrics.AUC(name='prc', curve='PR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_lstm.predict(temp_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auc(temp_y_test, y_pred)\n",
    "prc(temp_y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
