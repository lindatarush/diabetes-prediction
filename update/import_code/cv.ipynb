{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation\n",
    "In this notebook, all the cross-validation pipeline will be conducted, including imputation\n",
    "feature selection, preprocessing, modeling and evaluation.\n",
    "\n",
    "Each process is abstracted and encapsulated in the sklearn.pipline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "import dataclasses\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cycler import cycler\n",
    "COLORS = [\n",
    "    \"#F27970\",\n",
    "    \"#BB9727\",\n",
    "    \"#54B345\",\n",
    "    \"#32B897\",\n",
    "    \"#05B9E2\",\n",
    "    \"#8983BF\",\n",
    "    \"#C76DA2\"\n",
    "]\n",
    "plt.rcParams['axes.prop_cycle'] = cycler(color=COLORS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# read the dataset\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataset.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m dataset\n",
      "File \u001b[0;32m~/miniforge3/envs/diab-logue/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/diab-logue/lib/python3.9/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniforge3/envs/diab-logue/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/diab-logue/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniforge3/envs/diab-logue/lib/python3.9/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset.csv'"
     ]
    }
   ],
   "source": [
    "# read the dataset\n",
    "dataset = pd.read_csv(\"dataset.csv\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset\n",
    "features = dataset.columns.to_list()\n",
    "features.remove(\"cls\")\n",
    "\n",
    "X = dataset[features]\n",
    "y = dataset[\"cls\"]\n",
    "\n",
    "numerical_cols = ['hba1c', 'fasting_glucose', 'ldl_c', 'hdl_c', 'potassium', 'age']\n",
    "categorical_cols = ['sex']\n",
    "\n",
    "#scaling the numerical columns\n",
    "def scale(X):\n",
    "    scaler = RobustScaler()\n",
    "    pipeline=ColumnTransformer([\n",
    "        ('num',scaler,numerical_cols),\n",
    "    ])\n",
    "\n",
    "    X_scaled = pipeline.fit_transform(X)\n",
    "    return X_scaled, pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "def impute(X, n_imputation):\n",
    "    print(\"the iteration of imputation is {}\".format(n_imputation))\n",
    "    rr = RandomForestRegressor()\n",
    "    imputer = IterativeImputer(estimator=rr, verbose=1, max_iter=n_imputation)\n",
    "    X_imputed = imputer.fit_transform(X)\n",
    "    return X_imputed, imputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Feature selection and preprocessing\n",
    "we will apply feature selection using Lasso with Grid Search nested cross-validation to locate the optimal\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(X, y):\n",
    "\n",
    "    lasso = LassoCV(cv=5)\n",
    "    lasso.fit(X, y)\n",
    "    select_model = SelectFromModel(lasso, prefit=True)\n",
    "\n",
    "    features_selected = []\n",
    "    for i, coef in enumerate(lasso.coef_):\n",
    "        if coef != 0:\n",
    "            features_selected.append(features[i])\n",
    "    alpha = lasso.alpha_\n",
    "    X_selected = select_model.transform(X)\n",
    "    print(\"feature selected: \", features_selected)\n",
    "    return X_selected, features_selected, select_model, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import hamming_loss, f1_score, average_precision_score, precision_recall_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from pydantic import BaseModel\n",
    "from typing import Any, Dict, List, Tuple\n",
    "from sklearn.model_selection import KFold\n",
    "import tensorflow as tf\n",
    "\n",
    "class TFDNN(BaseEstimator, ClassifierMixin):\n",
    "    '''\n",
    "    sklearn compatible version of TensorFlow DNN\n",
    "    '''\n",
    "\n",
    "    def __init__(self, p:float=1.0) -> None:\n",
    "        \n",
    "    # Create the Sequential model\n",
    "        self.p = p\n",
    "        self.model = tf.keras.Sequential([\n",
    "        # Input layer with a flexible input shape and first hidden layer with 16 units\n",
    "            tf.keras.layers.Dense(16, activation='relu'),\n",
    "            tf.keras.layers.Dense(32, activation='relu'),\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "            tf.keras.layers.Dense(32, activation='relu'),\n",
    "            tf.keras.layers.Dense(16, activation='relu'),\n",
    "            tf.keras.layers.Dropout(rate=p),\n",
    "            tf.keras.layers.Dense(4, activation='softmax')\n",
    "        ])\n",
    "        self.model.compile(optimizer=\"adam\", loss=tf.keras.losses.CategoricalCrossentropy(), metrics=[tf.keras.metrics.F1Score(average=\"weighted\")])\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y, batch_size=32, epochs=10)\n",
    "        \n",
    "    def predict_prob(self, X):\n",
    "        return self.model(X)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return tf.argmax(self.model.predict(X_comp), axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_pred, y, save_path, classes):\n",
    "    '''\n",
    "    Plot the confusion matrix of multi-label classification.\n",
    "    \n",
    "    Args:\n",
    "        y_pred (List[int]): Predicted labels by the model, categorized by 0, 1, 2, 3.\n",
    "        y (List[int]): Ground truth labels, categorized by 0, 1, 2, 3.\n",
    "        save_path: the path for saving the result plot.\n",
    "        classes (List[str]): List of class names corresponding to each label.\n",
    "    '''\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    # Normalize confusion matrix\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=\"Pastel1\")\n",
    "    plt.title('Confusion matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"figures/\" + save_path + \".svg\", format=\"svg\", dpi=1400)\n",
    "    # plt.show()\n",
    "\n",
    "def plot_auc(y_pred, y, save_path, classes):\n",
    "    '''\n",
    "    Plot the one-versus-rest AUC curve.\n",
    "    \n",
    "    Args:\n",
    "        y_pred predict probability of each class\n",
    "        y (List[int]): Ground truth labels, categorized by 0, 1, 2, 3.\n",
    "        classes (List[str]): List of class names corresponding to each label.\n",
    "    '''\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y)\n",
    "    y_bin = lb.transform(y)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for i in range(len(classes)):\n",
    "        auc = roc_auc_score(y_bin[:, i], y_pred[:, i])\n",
    "        fpr, tpr, _ = roc_curve(y_bin[:, i], y_pred[:, i])\n",
    "        plt.plot(fpr, tpr, lw=2, label='%s (AUC = %0.2f)' % (classes[i], auc))\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('1 - Specificity')\n",
    "    plt.ylabel('Sensitivity')\n",
    "    plt.title('One-vs-Rest ROC AUC Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(\"figures/\" + save_path + \".svg\", dpi=1400, format=\"svg\")\n",
    "    # plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    {\n",
    "        \"name\": \"lr\",\n",
    "        \"estimator\": LogisticRegression,\n",
    "        \"params\": {\"penalty\": [\"l1\", \"l2\"], \"C\":[0.01, 0.1, 1, 10, 100, 1000],'solver':['liblinear']}\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"svm\",\n",
    "        \"estimator\": SVC,\n",
    "        \"params\": {\"C\":[0.01, 0.1, 1, 10, 100, 1000],'kernel': ['rfb', 'linear'], \"probability\":[True]}\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"rfc\",\n",
    "        \"estimator\": RandomForestClassifier,\n",
    "        \"params\": {\"n_estimators\": [10, 100, 1000], \"criterion\": [\"gini\", \"entropy\", \"log_loss\"]}\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"xgboost\",\n",
    "        \"estimator\": XGBClassifier,\n",
    "        \"params\": {\"learning_rate\": [1e-1, 1e-2, 1e-3,], \"max_depth\":[3, 4, 6], \"n_estimators\": [10, 100, 100]}\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"dnn\",\n",
    "        \"estimator\": MLPClassifier,\n",
    "        \"params\": {\"hidden_layer_sizes\":[[16,32,64,32,16], [16,32,32]],\"learning_rate_init\": [1e-2, 1e-3, 1e-4, 1e-5]}\n",
    "    }\n",
    "\n",
    "]\n",
    "\n",
    "result = {\n",
    "        \"alpha\":[],\n",
    "        \"features_selected\": [],\n",
    "        \"test_set\": [],\n",
    "        \"training_set\": []\n",
    "    }\n",
    "for model in models:\n",
    "    result.update({\n",
    "        model[\"name\"]: {\n",
    "                \"hamming_loss\": [],\n",
    "                \"f1_macro\": [],\n",
    "                \"f1_weighted\": [],\n",
    "                \"precision0\":[],\n",
    "                \"precision1\":[],\n",
    "                \"precision2\":[],\n",
    "                \"precision3\":[],\n",
    "                \"recall0\": [],\n",
    "                \"recall1\": [],\n",
    "                \"recall2\": [],\n",
    "                \"recall3\": [],\n",
    "                \"average_precision0\": [],\n",
    "                \"average_precision1\": [],\n",
    "                \"average_precision2\": [],\n",
    "                \"average_precision3\": [],\n",
    "                \"tpr0\": [],\n",
    "                \"tpr1\": [],\n",
    "                \"tpr2\": [],\n",
    "                \"tpr3\": [],\n",
    "                \"fpr0\": [],\n",
    "                \"fpr1\": [],\n",
    "                \"fpr2\": [],\n",
    "                \"fpr3\": [],\n",
    "                \"auc0\": [],\n",
    "                \"auc1\": [],\n",
    "                \"auc2\": [],\n",
    "                \"auc3\": [],\n",
    "                \"cache\": []\n",
    "            }\n",
    "    })\n",
    "classes = [\"g0\", \"g1\", \"g2\", \"g3\"]\n",
    "\n",
    "def train(X, y, models):\n",
    "    best_estimators = {}\n",
    "    for model in models:\n",
    "        params = model[\"params\"]\n",
    "        name = model[\"name\"]\n",
    "        # Grid search for the parameters\n",
    "        # use weighted score to take the imbalance into account\n",
    "        gs = GridSearchCV(model[\"estimator\"](), cv=5, param_grid=params, scoring=\"f1_weighted\") \n",
    "        gs.fit(X, y)\n",
    "        best_estimators[name] = {\n",
    "            \"estimator\": gs.best_estimator_,\n",
    "            \"params\": gs.best_params_\n",
    "        }\n",
    "    return best_estimators\n",
    "\n",
    "def evaluate(estimator, X_test, y_test, eval_result, iter_num):\n",
    "    model_name = estimator.__class__.__name__\n",
    "    y_test_pred = estimator.predict(X_test)\n",
    "    y_test_pred_prob = estimator.predict_proba(X_test)\n",
    "    eval_result[\"hamming_loss\"].append(hamming_loss(y_pred =y_test_pred, y_true=y_test))\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_bin = lb.transform(y_test)\n",
    "    f1_macro = f1_score(y_true=y_test, y_pred=y_test_pred, average='macro')\n",
    "    f1_weighted = f1_score(y_true=y_test, y_pred=y_test_pred, average='weighted')\n",
    "    eval_result[\"f1_macro\"].append(f1_macro)\n",
    "    eval_result[\"f1_weighted\"].append(f1_weighted)\n",
    "    eval_result[\"cache\"].append(estimator)\n",
    "    \n",
    "    # plot metrics\n",
    "    file_name = model_name + f\"-Iter-{iter_num}\"\n",
    "    plot_confusion_matrix(y_test_pred, y_test, file_name + \"-ConfusionMatrix\", classes)\n",
    "\n",
    "    plot_auc(y_test_pred_prob, y_test, file_name + \"-AUC\", classes)\n",
    "    for i in range(len(classes)):\n",
    "        fpr, tpr, _ = roc_curve(y_bin[:, i], [pred[i] for pred in y_test_pred_prob])\n",
    "        eval_result[f\"fpr{i}\"].append(fpr)\n",
    "        eval_result[f\"tpr{i}\"].append(tpr)\n",
    "        auc = roc_auc_score(y_bin[:, i], [pred[i] for pred in y_test_pred_prob])\n",
    "        eval_result[f\"auc{i}\"].append(auc)\n",
    "\n",
    "        precision, recall, _ = precision_recall_curve(y_bin[:, i], [pred[i] for pred in y_test_pred_prob])\n",
    "        average_precision = average_precision_score(y_bin[:, i], [pred[i] for pred in y_test_pred_prob])\n",
    "        eval_result[f\"precision{i}\"].append(precision)\n",
    "        eval_result[f\"recall{i}\"].append(recall)\n",
    "        eval_result[f\"average_precision{i}\"].append(average_precision)\n",
    "        \n",
    "\n",
    "def cross_validate(X, y, n_splits):\n",
    "    '''\n",
    "    cross-validate the models\n",
    "    '''\n",
    "    kf = StratifiedKFold(n_splits=n_splits)\n",
    "    \n",
    "\n",
    "    for iter, (train_index, test_index) in enumerate(kf.split(X, y)):\n",
    "        print(\"For the iteration: {}\".format(iter), \"#\" * 30)\n",
    "        X_train = X.loc[train_index]\n",
    "        y_train = y.loc[train_index]\n",
    "        X_test = X.loc[test_index]\n",
    "        y_test = y.loc[test_index]\n",
    "        \n",
    "        X_train_scaled, scaler = scale(X_train)\n",
    "\n",
    "        n_imputation = dataset[features].isnull().mean().mean() * 100 // 1\n",
    "        n_imputation = int(n_imputation)\n",
    "        X_train_imputed, imputer = impute(X_train_scaled, n_imputation)\n",
    "        \n",
    "        X_train_selected, features_selected, selector, alpha = select_features(X_train_imputed, y_train)\n",
    " \n",
    "        best_estimators = train(X_train_selected, y_train, models)\n",
    "        result[\"features_selected\"].append(features_selected)\n",
    "        result[\"alpha\"].append(alpha)\n",
    "        ### evaluate\n",
    "        \n",
    "        for process in [scaler, imputer, selector]:\n",
    "            X_test = process.transform(X_test)\n",
    "\n",
    "        # get the reference of the current test_set\n",
    "        result[\"test_set\"].append((X_test, y_test))\n",
    "        result[\"training_set\"].append((X_train_selected, y_train))\n",
    "        # evaluate the metrics for each iteration\n",
    "        for name, value in best_estimators.items():\n",
    "            evaluate(estimator=value[\"estimator\"], X_test=X_test, y_test=y_test, eval_result=result[name], iter_num=iter)\n",
    "                \n",
    "\n",
    "cross_validate(X.head(500), y.head(500), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresult\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_recall_precision_curve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do some housework\n",
    "\n",
    "collect the data and write to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st \n",
    "\n",
    "\n",
    "def CI(samples, alpha = 0.95):\n",
    "    mean = np.mean(samples)\n",
    "    left, right = st.norm.interval(confidence = alpha, loc = mean, scale = st.sem(np.array(samples)))\n",
    "    res = [left , mean, right]\n",
    "    func = lambda x : \"{}%\".format(round(x * 100, 2))\n",
    "    return list(map(func, res))\n",
    "\n",
    "\n",
    "model_names = [item[\"name\"] for item in models]\n",
    "performances = {\n",
    "    \"model\": [],\n",
    "    \"f1_macro\":[],\n",
    "    \"f1_weighted\": [],\n",
    "    \"hamming_loss\": [],\n",
    "    \"auc0\": [],\n",
    "    \"auc1\": [],\n",
    "    \"auc2\": [],\n",
    "    \"auc3\": [],\n",
    "}\n",
    "\n",
    "for name in model_names:\n",
    "    performances[\"model\"].append(name)\n",
    "    for metric in performances.keys():\n",
    "        if metric == \"model\":\n",
    "            continue\n",
    "        samples = result[name][metric]\n",
    "        ci = CI(samples)\n",
    "        performances[metric].append(ci)\n",
    "\n",
    "performances_df = pd.DataFrame(performances)\n",
    "performances_df.to_csv(\"csv/model_performace.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performances_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "Need to select features set first, then compare the model performance(over cross-validation) to find the most optimal model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the optimum features set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the optimum based on alpha, need to check the \n",
    "optimum_index = np.argmin(result[\"alpha\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# take rfc for example\n",
    "optimal_model = result[\"rfc\"][\"cache\"][optimum_index]\n",
    "\n",
    "def save_model(file_name: str, model):\n",
    "    with open(\"models/\"+file_name,'wb') as f:\n",
    "        pickle.dump(model,f)\n",
    "save_model(\"rfc.pkl\", optimal_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shapely Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to choose the best model, here just use lr as an example\n",
    "estimator = result[\"lr\"][\"cache\"][optimum_index]\n",
    "X_test_optimal, y_test_optimal = result[\"test_set\"][optimum_index]\n",
    "X_test_optimal = pd.DataFrame(X_test_optimal, columns=result[\"features_selected\"][optimum_index])\n",
    "explainer = shap.KernelExplainer(estimator.predict_proba, X_test_optimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer(X_test_optimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"features_selected\"][optimum_index]\n",
    "result[\"features_selected\"][optimum_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"g0\", \"g1\", \"g2\", \"g3\"]\n",
    "values_list = [shap_values[:, :, cls_ind] for cls_ind in range(len(classes))]\n",
    "shap.summary_plot(values_list, feature_names=result[\"features_selected\"][optimum_index],plot_type=\"bar\", show=False, plot_size=0.5)\n",
    "plt.gcf().set_size_inches(10, 2)\n",
    "plt.legend().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_shap_beeswarm(values_list, features):\n",
    "    # Setting figure size and DPI for high-resolution outputs\n",
    "    fig = plt.figure(figsize=(12, 42))\n",
    "    \n",
    "    for i in range(4):\n",
    "        plt.subplot(2, 2, i + 1)\n",
    "        # Generate SHAP beeswarm plot\n",
    "        ax = shap.plots.beeswarm(values_list[i], show=False, color_bar= i%2 != 0, plot_size=1, color_bar_label=\"\").axes\n",
    "        \n",
    "        # Set axis labels and title\n",
    "        ax.set_xlabel(f\"SHAP Value (Group {i + 1})\", fontsize=10)\n",
    "        \n",
    "        # Set y-axis labels\n",
    "        if i % 2 != 0:\n",
    "            ax.set_yticklabels([\"\" for _ in features])\n",
    "\n",
    "        # Adjusting tick parameters for better visibility\n",
    "        ax.tick_params(axis='both', which='major', labelsize=10)\n",
    "        plt.subplots_adjust(left=0.3, right=0.9, top=0.95, bottom=0.05, hspace=1)\n",
    "    # Adjust layout to prevent overlapping\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"figures/beeswarm.svg\", format=\"svg\", dpi=1400)\n",
    "\n",
    "plot_shap_beeswarm(values_list, result[\"features_selected\"][optimum_index])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Color is used to display the original value of a feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree-based Interpretation \n",
    "\n",
    "This is left blank for now.\n",
    "\n",
    "\"\n",
    "To select the lower probability threshold for the very high group, all possible predicted probabilities\n",
    "were with a positive likelihood ratio greater than or equal to 10 were selected. Any of these could\n",
    "arbitrarily be used as the threshold, we have selected to use the lowest value to maximize the\n",
    "number of patients classed into this risk group.\n",
    "Next, possible probability thresholds greater than or equal to the very high group threshold were\n",
    "removed, and the selection process was repeated to find the threshold for the high risk group, this\n",
    "time looking for a positive likelihood ratio of 5 or greater. The lowest such value was selected.\n",
    "For the very low risk group, probability thresholds less than the threshold for the high risk group,\n",
    "with negative likelihood ratio of 0.1 or less were selected, and the highest such value was used as\n",
    "the upper probability threshold for the very low risk group. Finally, for the low risk group, values\n",
    "greater than the very low risk group threshold, smaller than the high risk group threshold, with\n",
    "negative likelihood ratios of 0.2 or less were selected, and the highest value was used as the upper\n",
    "probability threshold for the low risk group.\n",
    "\"\n",
    "\n",
    "--Montgomery-Csobán, T., Kavanagh, K., Murray, P., Robertson, C., Barry, S. J., Ukah, U. V., ... & Widmer, M. (2024). Machine learning-enabled maternal risk assessment for women with pre-eclampsia (the PIERS-ML model): a modelling study. The Lancet Digital Health, 6(4), e238-e250."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the descriptions, the algorithm can be demonstrated as follow steps:\n",
    "1. Calculate the LR+, and LR- for each group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
