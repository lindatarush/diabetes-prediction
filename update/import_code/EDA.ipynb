{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Cleaning Process and Exploration Analysis\n",
    "**This notebook serves as the main data cleaning and processing module**\n",
    "\n",
    "In this notebook , I will \n",
    "1. Combine all the diagnosis records from different sections.\n",
    "2. Implement the chronological filtering to determine the earliest date of pre-diabetes and diabetes. \n",
    "3. Merge with demographic information and calculate the age of each time point(pre, diab, death)\n",
    "4. Exclude some invalid records and label the patients.\n",
    "5. Do the exploration analysis where I will give out the basic statistic and plot various of charts to illustrate the basic demographic outlines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For clarity: we name all the pre-diabetes patients with prefix pre,diabetes patients with prefix diab and the patients progressed from pre-diabetes to diabetes with prefix pre2Diab.\n",
    "\n",
    "We also label the abnormal patients as follow:\n",
    "- Pre-diabetes Patient (Only have pre-diabetes): 0\n",
    "- Pre-diabetes to Diabetes paitient (the patients who has sign of pre-diabetes BEFORE they are diagosed with diabetes): 1\n",
    "- Diabetes (Only have diabetes or have earlier confirmed as diabetes than pre-diabetes): 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%load_ext autoreload\n",
    "import datetime\n",
    "import random\n",
    "import time\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "import seaborn as sns\n",
    "from typing import *\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS = [\n",
    "    \"#F27970\",\n",
    "    \"#BB9727\",\n",
    "    \"#54B345\",\n",
    "    \"#32B897\",\n",
    "    \"#05B9E2\",\n",
    "    \"#8983BF\",\n",
    "    \"#C76DA2\"\n",
    "]\n",
    "\n",
    "COLORS\n",
    "COLOR_MAP = shap.plots.colors.red_blue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 Generate Pseudo Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = {\n",
    "    \"lab_tests\" : [\"hba1c\", \"fasting_glucose\", \"creatinine\", \"ldl_c\", \"hdl_c\", \"triglyceride\", \"potassium\"],\n",
    "    \"demographic\" : [\"age\", \"sex\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Combine All The Records From Different  Sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read all the table we want from disk:\n",
    "- Lab Test result\n",
    "- Diagnosis result (Diabetes Only)\n",
    "- Family Medicine\n",
    "- DMCS\n",
    "- Medication (drug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'../tables/output'\n",
    "\n",
    "# read the diag result from each tables\n",
    "lab_diag = pd.read_csv(r'../tables/output/first_diag_lab.csv', index_col=0)\n",
    "dx_diag = pd.read_csv(r'../tables/output/first_diag_dx.csv', index_col=0)\n",
    "fm_diag = pd.read_csv(r'../tables/output/first_diag_fm.csv', index_col=0)\n",
    "dmcs_diag = pd.read_csv(r'../tables/output/first_diag_dmcs.csv', index_col=0)\n",
    "drug_diag = pd.read_csv(r'../tables/output/first_diag_drug.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the diagnosis together\n",
    "combine = pd.concat([lab_diag, dx_diag, fm_diag, dmcs_diag, drug_diag]).reset_index(drop=True)\n",
    "combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the data type\n",
    "combine[\"diff_hour\"] = combine[\"diff_hour\"].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implement the Chronological Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we got the patient diagnosis of pre-diabetes and diabetes for every patient. we need to seperate them into three groups:\n",
    "1. group 0: no pre-diabetes or diabetes records were earlier than pre-diabetes\n",
    "2. group 1: only pre-diabetes\n",
    "3. group 2: pre-diabetes to diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "def chronoFilter(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    callable object than can apply splittng rules that define each patient labels on each patient records. The splitting \n",
    "    rules are defined as follow:\n",
    "    - Pre-diabetes Patient (Only have pre-diabetes): 0\n",
    "    - Pre-diabetes to Diabetes paitient (the patients who has sign of pre-diabetes BEFORE they are diagosed with diabetes): 1\n",
    "    - Diabetes (Only have diabetes or have earlier confirmed as diabetes than pre-diabetes): 2\n",
    "    \n",
    "    Args:\n",
    "        df: grouped data frame that is waiting to be aggregated\n",
    "    Return:\n",
    "        aggregated data frame\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    dim = df.shape[0]\n",
    "    assert dim <= 2 # make sure there are only earliest record(s) in this dataframe\n",
    "    \n",
    "    # one record only situation\n",
    "    if dim == 1: \n",
    "        if df.iloc[0][\"diab_type\"] == \"pre\":\n",
    "            return pd.DataFrame({\n",
    "                \"pseudo_patient_key\":[df.iloc[0,0]], \n",
    "                \"pre_dtm\": [df.iloc[0,1]],\n",
    "                \"diab_dtm\": [np.nan],\n",
    "                \"pre_diff_hour\": [df.iloc[0,2]],\n",
    "                \"diab_diff_hour\": [np.nan],\n",
    "                \"pre_src\": [df.iloc[0,4]],\n",
    "                \"diab_src\":[np.nan],\n",
    "                \"label\": [0]\n",
    "            })\n",
    "        else: #diabetes\n",
    "            return pd.DataFrame({\n",
    "            \"pseudo_patient_key\":[df.iloc[0,0]], \n",
    "            \"pre_dtm\": [np.nan], \n",
    "            \"diab_dtm\": [df.iloc[0,1]],\n",
    "            \"pre_diff_hour\": [np.nan],\n",
    "            \"diab_diff_hour\": [df.iloc[0,2]],\n",
    "            \"pre_src\": [np.nan],\n",
    "            \"diab_src\":[df.iloc[0,4]],\n",
    "            \"label\": [2]\n",
    "        })\n",
    "        \n",
    "    # two records situation\n",
    "    else: \n",
    "        if df.iloc[0][\"diff_hour\"] > df.iloc[1][\"diff_hour\"]: # pre to diabetes\n",
    "            return pd.DataFrame({\n",
    "            \"pseudo_patient_key\":[df.iloc[0,0]], \n",
    "            \"pre_dtm\": [df.iloc[1,1]], \n",
    "            \"diab_dtm\": [df.iloc[0,1]],\n",
    "            \"pre_diff_hour\": [df.iloc[1,2]],\n",
    "            \"diab_diff_hour\": [df.iloc[0,2]],\n",
    "            \"pre_src\": [df.iloc[1,4]],\n",
    "            \"diab_src\":[df.iloc[0,4]],\n",
    "            \"label\": [1]\n",
    "        })\n",
    "        else: # diabetes to pre\n",
    "            return pd.DataFrame({\n",
    "            \"pseudo_patient_key\":[df.iloc[0,0]], \n",
    "            \"pre_dtm\": [np.nan], \n",
    "            \"diab_dtm\": [df.iloc[0,1]],\n",
    "            \"pre_diff_hour\": [np.nan],\n",
    "            \"diab_diff_hour\": [df.iloc[0,2]],\n",
    "            \"pre_src\": [np.nan],\n",
    "            \"diab_src\":[df.iloc[0,4]],\n",
    "            \"label\": [2]\n",
    "        })\n",
    "\n",
    "        \n",
    "#######################################################################################\n",
    "# get the row number \n",
    "rnk = tools.row_number(combine, \"pseudo_patient_key\", \"diab_type\", sort_key=\"diff_hour\")\n",
    "# get the earliest records for each patient each diab type\n",
    "el_rec = combine[rnk == 1].sort_values([\"pseudo_patient_key\", \"diab_type\"])\n",
    "# apply the rules on the dataframe\n",
    "group_patient = el_rec.groupby(by=\"pseudo_patient_key\").apply(chronoFilter)\n",
    "# write the data to disk\n",
    "group_patient.to_csv(\"../tables/output/group_patient.csv\")\n",
    "\n",
    "min = (time.time() - start) / 60\n",
    "print(\"runtime: {:.4f} minutes\".format(min))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Merge with demographic information and test results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Demographic Infomation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the file of patient demographic information\n",
    "patient_info = tools.fileReader(r\"../DATAFILE\", 'patient_data')\n",
    "# read the grouped patients\n",
    "group_patient = pd.read_csv(r\"../tables/output/group_patient.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = group_patient\n",
    "right = patient_info[[\"pseudo_patient_key\", \"dob_Y\", \"sex\", \"death_date_Y\", \"diff_in_hour_death_date\"]]\n",
    "diab_patients_info = pd.merge(left=left, right=right, how='left', on='pseudo_patient_key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the age of each date time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_age(df, fields, dob=\"dob_Y\"):\n",
    "    '''\n",
    "    map the date time fieds into age inplace\n",
    "    Args:\n",
    "        field: date fields\n",
    "        dob: date of birth\n",
    "    '''\n",
    "        \n",
    "    age_fields = list(map(lambda x : x.split(r'_')[0] + \"_age\", fields))\n",
    "    for af, f in zip(age_fields, fields):\n",
    "        df[af] = (pd.to_datetime(df[f]) - pd.to_datetime(df[dob])).apply(lambda x : x / np.timedelta64(1, \"Y\"))\n",
    "        \n",
    "######################################################################################################################  \n",
    "\n",
    "# replace null value to np.nan\n",
    "diab_patient_age = diab_patients_info.replace(r'\"\"', np.nan)\n",
    "# map the date time fields into age inplace\n",
    "map_age(diab_patient_age, [\"pre_dtm\", \"diab_dtm\", \"death_date_Y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Pseudo patient data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_date(start_year=2003, end_year=2019):\n",
    "    # Generate a random date within the specified range\n",
    "    start_date = datetime.date(start_year, 1, 1)\n",
    "    end_date = datetime.date(end_year, 12, 31)\n",
    "    days_between = (end_date - start_date).days\n",
    "    random_days = random.randint(0, days_between)\n",
    "    random_date = start_date + datetime.timedelta(days=random_days)\n",
    "    return random_date.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000\n",
    "data = {}\n",
    "for lt in FEATURES[\"lab_tests\"]:\n",
    "    low = np.random.randint(0,100)\n",
    "    data[lt] = [np.random.uniform(low, low+20) if np.random.uniform(0, 1) > np.random.uniform(0, 1) * 0.5 else np.nan for _ in range(N)]\n",
    "    \n",
    "data[\"age\"] = np.random.uniform(18, 120, N)\n",
    "data[\"sex\"] = (np.random.uniform(0, 1, N) < 0.45).astype(\"int\")\n",
    "data[\"diab_diff_hour\"] = np.random.randint(1000,10000, N)\n",
    "data[\"diff_in_hour_death_date\"] = [np.random.randint(10000, 15000) if np.random.uniform(0, 1) < 0.2 else np.nan for _ in range(N)]\n",
    "data[\"pre_diff_hour\"] = data[\"diab_diff_hour\"] - np.random.randint(100, 1000)\n",
    "data[\"dob_Y\"] = np.random.randint(1965, 1996, N).astype(\"str\")\n",
    "data[\"label\"] = np.random.randint(0, 3, N)\n",
    "data[\"pre_dtm\"] = [generate_random_date() for _ in range(N)]\n",
    "data[\"pre_age\"] = map(lambda x : int(x[:4]), data[\"pre_dtm\"])\n",
    "diab_patient_age = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Exclusion and Labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Exclusion\n",
    "exclusion criterial:\n",
    " - Enrolment in last {{TIME_SPEC}} (pre_dtm <= {{CUT_OFF}})\n",
    " - Follow up time is less than {{TIME_SPEC}}, we want to exclude the patients who exited the investigation out of death.\n",
    " - Diabetes only.\n",
    " - Patients younger than 18 (pre_age < 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to year of birth\n",
    "diab_patient_age[\"dob_Y\"] = diab_patient_age[\"dob_Y\"].apply(lambda x : x[:4]).astype(\"int\")\n",
    "# compute the progression period in hours\n",
    "diab_patient_age[\"prog_pd\"] = diab_patient_age[\"diab_diff_hour\"] - diab_patient_age[\"pre_diff_hour\"] \n",
    "diab_patient_age[\"diff_in_hour_death_date\"] = diab_patient_age[\"diff_in_hour_death_date\"].astype(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_FT = 30.5 * 24\n",
    "# exclusion\n",
    "\n",
    "def show_num():\n",
    "    print(\"total: \", diab_patient_excluded.shape[0], \n",
    "    \"label 0: \", diab_patient_excluded.query(\"label == 0\").shape[0], \n",
    "    \"label 1: \", diab_patient_excluded.query(\"label == 1\").shape[0]\n",
    "    )\n",
    "    \n",
    "diab_patient_excluded = diab_patient_age.copy() # create a new reference\n",
    "\n",
    "show_num()\n",
    "# we first exclude the patients with label 2(diabetes before pre-diabetes)\n",
    "diab_patient_excluded = diab_patient_excluded.query(\"~(label == 2)\")\n",
    "show_num()\n",
    "# we exclude the patients who died before possibly diagnosed with T2DM\n",
    "diab_patient_excluded = diab_patient_excluded.query(\"~(label == 0 and diff_in_hour_death_date.notnull())\")\n",
    "show_num()\n",
    "# we exclude the patients who exit the cohort before possibly diagnosed with T2DM\n",
    "TIME_SPEC = 10\n",
    "CUT_OFF = '{year}-12-31'.format(year=2019-TIME_SPEC)\n",
    "diab_patient_excluded = diab_patient_excluded.query(\"~(label == 0 and pre_dtm > '{CUT_OFF}')\")\n",
    "show_num()\n",
    "# Patients younger than 18(pre_age < 18)\n",
    "diab_patient_excluded = diab_patient_excluded.query(\"pre_age >= 18\")\n",
    "show_num()\n",
    "\n",
    "# # Follow-up time less than 1 month i.e. 30.5*24 hours\n",
    "# diab_patient_age = diab_patient_age.query(f\"prog_pd > {MIN_FT} | prog_pd.isnull()\", engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diab_patient_age = diab_patient_age.assign(prog_pd = diab_patient_age[\"diab_diff_hour\"] - diab_patient_age[\"pre_diff_hour\"])\n",
    "year_hours = 24 * 365.25\n",
    "def cls_mapper(prog_pd: float) -> int:\n",
    "    if prog_pd < 2 * year_hours:\n",
    "        return 0\n",
    "    elif prog_pd < 5 * year_hours:\n",
    "        return 1\n",
    "    elif prog_pd < 10 * year_hours:\n",
    "        return 2\n",
    "    return 3\n",
    "\n",
    "# uncomment it in the HA\n",
    "# diab_patient_excluded[\"cls\"] = diab_patient_excluded[\"prog_pd\"].apply(cls_mapper)\n",
    "diab_patient_excluded[\"cls\"] = np.random.randint(0, 4, diab_patient_excluded.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Explanatory Analysis\n",
    "I will plot distribution plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define helper functions\n",
    "def plot_barchart(s:pd.Series, n_bin:int, bin_width:int=1, sort=False, title=\"\"):\n",
    "    bin = pd.cut(s, bins=[bin_width * i for i in range(n_bin)])\n",
    "    out = bin.value_counts(sort=sort)\n",
    "    ax = out.plot.bar(rot=0, color='b', figsize=(6,4))\n",
    "    ax.set_xticklabels([bin_width * x for x in range(n_bin)])\n",
    "    ax.set_title(title)\n",
    "\n",
    "def plot_boxplot(df, cat, title):\n",
    "    # boxplot for death age\n",
    "    fig, axs = plt.subplots(1,len(cat))\n",
    "    fig.suptitle(title)\n",
    "    for idx, name in zip(range(len(cat)), cat):\n",
    "        data = df[df.label == idx][\"death_age\"]\n",
    "        axs[idx].boxplot(data, 0, '')\n",
    "        axs[idx].set_title(name)\n",
    "    \n",
    "\n",
    "def show_number(df):\n",
    "    tools.getNum(df, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 BoxPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# violin plot\n",
    "def plot_box(df: pd.DataFrame, features: Sequence[str], cls=\"cls\"):\n",
    "\n",
    "    # Create the figure and axes object\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    n = len(features) // 3 + 1\n",
    "    for i, feature in enumerate(features):\n",
    "        df_melted = df[[feature, cls]].melt(id_vars=cls, value_vars=feature,\n",
    "                        var_name=\"Measurements\", value_name=\"Value\")\n",
    "        ax = plt.subplot(n, 3, i+1)\n",
    "\n",
    "        # Creating the violin plot on the axes object\n",
    "        colors = {}\n",
    "        for i, color in enumerate(COLORS):\n",
    "            colors[i] = color\n",
    "        sns.despine(left=True)\n",
    "        ax = sns.violinplot(x=\"Measurements\", y=\"Value\", hue=\"cls\", data=df_melted, palette=colors, gap=0.75)\n",
    "        ax.set_xlabel(\"\")\n",
    "        ax.set_ylabel(\"\")\n",
    "        plt.legend().set_visible(False)\n",
    "\n",
    "\n",
    "features = []\n",
    "features.extend(FEATURES[\"lab_tests\"])\n",
    "features.extend(FEATURES[\"demographic\"])\n",
    "\n",
    "plot_box(diab_patient_excluded, features)\n",
    "fig.subplots_adjust(hspace=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diab_patient_excluded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Correlation Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "corr_matrix = diab_patient_excluded[features].corr()\n",
    "# Set up the matplotlib figure\n",
    "_ = plt.figure(figsize=(10, 8))\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "ax = sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"tab10\", cbar_kws={'label': 'Correlation coefficient'})\n",
    "plt.savefig(\"correlation_plot.svg\", format=\"svg\", dpi=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import kruskal, chi2_contingency\n",
    "import scipy.stats as stats\n",
    "# Load the dataset\n",
    "\n",
    "\n",
    "# Define the features and the group\n",
    "features = [\"hba1c\", \"fasting_glucose\", \"creatinine\", \"ldl_c\", \"hdl_c\", \"triglyceride\", \"potassium\", \"age\", \"sex\"]\n",
    "\n",
    "group = 'cls'\n",
    "\n",
    "statistics = [\"missing_rate\",\n",
    "    \"pvalue\",\n",
    "    \"g0_mean\",\n",
    "    \"g1_mean\",\n",
    "    \"g2_mean\",\n",
    "    \"g3_mean\",\n",
    "    \"g0_std\",\n",
    "    \"g1_std\",\n",
    "    \"g2_std\",\n",
    "    \"g3_std\",\n",
    "    \"g0_iqr\",\n",
    "    \"g1_iqr\",\n",
    "    \"g2_iqr\",\n",
    "    \"g3_iqr\",\n",
    "]\n",
    "\n",
    "class StatTape():\n",
    "\n",
    "    missing_rate = []\n",
    "    pvalue = []\n",
    "\n",
    "    g0_mean = []\n",
    "    g1_mean = []\n",
    "    g2_mean = []\n",
    "    g3_mean = []\n",
    "\n",
    "    g0_std = []\n",
    "    g1_std = []\n",
    "    g2_std = []\n",
    "    g3_std = []\n",
    "\n",
    "    g0_iqr = []\n",
    "    g1_iqr = []\n",
    "    g2_iqr = []\n",
    "    g3_iqr = []\n",
    "\n",
    "def stat_append(name: str, value: Any):\n",
    "    getattr(StatTape, name).append(value)\n",
    "\n",
    "for feature in features:\n",
    "    # perform chi square test\n",
    "    stat_append(\"missing_rate\", diab_patient_excluded[feature].isnull().mean())\n",
    "    if feature == \"sex\":\n",
    "        table = []\n",
    "        for label in [0,1,2,3]:\n",
    "            female = diab_patient_excluded.query(f\"cls == {label} and sex == 0\").count()\n",
    "            male = diab_patient_excluded.query(f\"cls == {label} and sex == 1\").count()\n",
    "            table.append([female, male])\n",
    "        pvalue = chi2_contingency(table).pvalue\n",
    "    else:\n",
    "        groups = diab_patient_excluded.groupby(group)[feature].apply(list)\n",
    "        pvalue = kruskal(*groups, nan_policy=\"omit\").pvalue\n",
    "\n",
    "    stat_append(\"pvalue\", pvalue)\n",
    "\n",
    "    for label in [0, 1, 2, 3]:\n",
    "        temp = diab_patient_excluded.query(f\"cls == {label}\")[feature]\n",
    "        mean = temp.mean()\n",
    "        std = temp.std()\n",
    "        iqr = stats.iqr(temp.to_list(), nan_policy=\"omit\")\n",
    "        stat_append(f\"g{label}_mean\", mean)\n",
    "        stat_append(f\"g{label}_std\", std)\n",
    "        stat_append(f\"g{label}_iqr\", iqr)\n",
    "\n",
    "d = {\"features\": features}\n",
    "for s in statistics:\n",
    "    d[s] = getattr(StatTape, s)\n",
    "feature_stats = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = diab_patient_excluded.copy() # create new reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Handling Missingness\n",
    "\n",
    "I will handle the missingness following steps:\n",
    "1. exclude the patients without HbA1c, Fasting Glucose.\n",
    "2. drop the variables that exceeds 30% missingness over the remaining population.\n",
    "3. check the missingness mechanism, and impute using MICE.\n",
    "4. mssingness not at random(MNAR) is ruled out from the discussion the given the natural of the clinical input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude the patients without HbA1c, Fasting Glucose\n",
    "dataset = dataset.query(\"hba1c.notnull() and fasting_glucose.notnull()\", engine=\"python\")\n",
    "\n",
    "# drop the variables that exceeds 25% missingness over the remaining population.\n",
    "mask = dataset[features].isnull().mean() < 0.25\n",
    "valid_features = dataset[features].columns[mask].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the missing mechanism\n",
    "def hold_out(name, targets):\n",
    "    res = []\n",
    "    for target in targets:\n",
    "        if target != name:\n",
    "            res.append(target)\n",
    "    return res\n",
    "\n",
    "def check_mm(valid_features, df, alpha=0.05):\n",
    "    '''\n",
    "    check the missing assumption\n",
    "    '''\n",
    "    res = {}\n",
    "    for target in valid_features:\n",
    "        remain_feature = hold_out(target, targets)\n",
    "        ds = df.copy()\n",
    "        if ds[target].isnull().sum() == 0:\n",
    "            res[target] = np.nan\n",
    "            continue \n",
    "\n",
    "        dummy = ds[target].isnull().astype(bool)\n",
    "        table = []\n",
    "        for label in [0,1,2,3]:\n",
    "            miss = ds[dummy].query(f\"cls == {label}\")[target].shape[0]\n",
    "            non_miss = ds[~dummy].query(f\"cls == {label}\")[target].shape[0]\n",
    "            table.append([miss, non_miss])\n",
    "            \n",
    "        result = chi2_contingency(table).pvalue\n",
    "        res[target] = \"significant\" if result < alpha else \"non-significant\"\n",
    "    return res\n",
    "\n",
    "check_mm(valid_features, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation\n",
    "a rule of thumb for determining the number of\n",
    "mputations is to use at least the percentage of incomplete cases or more[1].\n",
    "\n",
    "The imputation should also be implemented within cross-validation[2].\n",
    "\n",
    "[1] Bodner, T. E. (2008). What improves with increased missing data imputations?. Structural equation modeling: a multidisciplinary journal, 15(4), 651-675.\n",
    "\n",
    "[2] https://missingdatasolutions.rbind.io/2021/02/mi-cross-validation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_and_features = valid_features\n",
    "label_and_features.append(\"cls\")\n",
    "dataset[label_and_features].to_csv(\"dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "## we will IterativeImputer\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
